%%-*-Latex-*-
\mychapter{Execution of the Code}
\label{chap:run}

The intention of this chapter is to provide a comprehensive prescription for
setting up and performing runs with the code.  Firstly, the main concepts
relating to the numerics of \PS are defined. Then the input file's structure
and format is described. The user is then taken through the process of setting
up the code to model a new machine, and finally an attempt is made to indicate
and solve the problems that the user will face whilst trying to achieve a
feasible solution.

\section{Main Concepts}

\subsection{Variable Descriptor File}

Great emphasis has already been placed on using the variable descriptor file
because of its role as an invaluable resource for the user of \PSD It acts as
a dictionary / reference manual for the code's variables, and contains the
following information about each:
\begin{itemize}
\item name
\item
type --- {\tt real} = single precision real; {\tt dble} = double precision
real; {\tt intg} = integer; {\tt char} = character string
\item
dimensions (of arrays)
\item
default value(s) of those variables that are not initially derived from a
combination of other values. The default values are mostly set in routine {\tt
INITIAL}
\item
description, including physical units if relevant
\item
for switches/flags, the meanings of all allowed values
\item
iteration variable number, if relevant
\item
corresponding constraint equation, if relevant
\end{itemize}
In addition, global code parameters are labelled {\tt PAR}. These can only be
changed by editing the relevant \INCLUDE file, but this should not be carried
out unless it is absolutely necessary.

All the variables that are shown with a default value are available to be
changed by the user using the input file (Section~\ref{sec:infile}), except
for those which are labelled {\tt FIX}. Variables not shown with a default
value are calculated by the code from a combination of other parameters, and
so it would be meaningless to initialise them.  Obviously, these variables
cannot be changed using the input file.

It is exceedingly important to keep the variable descriptor file up to date.

\subsection{Input Parameters}
\label{sec:inpars}

Input parameters make up a large proportion of the variables listed in the
variable descriptor file. They comprise all those variables that, once set in
the initialisation routine or redefined in the input file, do not change
throughout a \PS run. In fact, only those variables defined as iteration
variables (Section~\ref{sec:itvars}) can change during the course of a run.

\subsection{Constraint Equations}
\label{sec:constraints}

Any computer program naturally contains myriads of equations. The built-in
equation solvers within \PS act on a special class, known as {\em constraint
equations}, all of which are formulated in routine {\tt CON1} in source file
{\tt eqns.f}. Table~\ref{tab:eqns} summarises the constraint equations
available in \PSD These can be split into two types --- (1) consistency
equations, that enforce consistency between the physics and engineering
parameters, and (2) limit equations, that enforce various parameters to lie
within their allowed limits. The {\tt neqns} constraint equations that the
user chooses for a given run are activated by including the equation numbers
in the first {\tt neqns} elements of array {\tt icc} in input block {\tt
INPT1}.

\subsubsection{Consistency equations}

Consistency equations are usually {\em equalities}\/ that ensure that the
machine produced by \PS is self-consistent. This means, therefore, that many
of these constraint equations should {\em always}\/ be used, namely
equations~1, 2, 10 and 11 (see Table~\ref{tab:eqns}).  Equation~7 should also
be activated if neutral beam injection is used and equation~15 should be used
if a pulsed machine ({\tt lpulse = 1}) is being modelled.  The other
consistency equations can be activated if required.

A typical consistency equation ensures that two functions $g$ and $h$ are
equal:
\begin{eqnarray*}
g(x,y,z,\ldots) & = & h(x,y,z,\ldots) \\
c_i & = & 1 - \frac{g}{h}
\end{eqnarray*}
The equation solvers VMCON and HYBRD need the constraint equations $c_i$ to be
given in the form shown, since they adjust the iteration variables so as to
obtain $c_i = 0$, thereby ensuring that $g = h$.

\subsubsection{Limit equations}

The limit equations are usually {\em inequalities}\/ that ensure that various
physics or engineering limits are not exceeded. Each of these equations has an
associated {\em f-value}, which allow them to be {\em coded}\/ as
equalities. The f-values are used as follows.

In optimisation mode, all iteration variables have prescribed lower and upper
bounds. In general, limit equations have the form

\[ \mbox{\it calculated quantity} = f \times \mbox{\it maximum allowable
value} \]

where $f$ is the f-value. If $f$ has a lower bound of zero and an upper bound
of one, then the limit equation does indeed constrain the calculated quantity
to lie between zero and its maximum allowable value, as required.

As with the consistency equations, the general form of the limit equations is
\[ c_i = 1 - f.\frac{g}{h} \]
where $g$ is the maximum allowed value of the quantity $h$.

Sometimes, the limit equation and f-value are used to ensure that quantity $h$
is {\em larger}\/ than its {\em minimum}\/ value $g$. In this case, $0 \leq f
\leq 1$ (as before), but the equation takes the form
\[ c_i = 1 - f.\frac{h}{g} \]

By fixing the f-value (i.e.\ not including it in the {\tt ixc} array), the
limit equations can be used as equality constraints. For example, to set the
net electric power to a certain value, the following should be carried out:
\begin{enumerate}
\item
Activate constraint equation 16 by including it in the first {\tt neqns}
elements of array {\tt icc} in input block {\tt INPT1}
\item
Set {\tt fpnetel = 1.0D0} in input block {\tt INEQDAT}
\item
Ensure that {\tt fpnetel} (iteration variable no.\ 25) {\em DOES NOT}\/ appear
in array {\tt ixc} in input block {\tt INPT1}
\item
Set {\tt pnetelin} in input block {\tt INEQDAT} to the required net electric
power
\end{enumerate}

Limit equations are not restricted to optimisation mode. In non-optimisation
mode, the iteration variables are not bounded, but the f-values can still be
used to provide information about how calculated values compare with limiting
values, without having to change the characteristics of the device being
benchmarked to find a solution.

It is for this reason that all the constraint equations used in \PS are
formulated as equalities, despite the fact that equation solver VMCON can
solve for inequalities as well. The use of f-values precludes this need, and
allows the non-optimising equation solver HYBRD to use the same constraint
equations.

\input{table_eqns} % Table summarising constraint equations

\subsection{Iteration Variables}
\label{sec:itvars}

It is necessary to calculate numerical derivatives during the solution of the
constraint equations. The iteration variables are the parameters that the
equation solvers use for this purpose --- all the other code variables (input
parameters --- see above) remain fixed at their initial value. Successive
calls are made to the physics and engineering routines, with slightly
different values for the iteration variables on each call, and the equation
solver determines the effect on the output due to these small changes to the
input (see Figures~\ref{fig:flow_hybrid} and \ref{fig:flow_vmcon}). The {\tt
nvar} iteration variables that the user chooses for a given run are activated
by including the variable numbers in the first {\tt nvar} elements of array
{\tt ixc} in input block {\tt INPT1}. Tables~\ref{tab:itvars1}
and~\ref{tab:itvars2} list the iteration variables available in \PSD

Clearly, the equation solvers need at least as many variables to iterate as
there are equations to solve, i.e.\ {\tt nvar} $\geq$ {\tt neqns}. If the run
is a non-optimising case, then {\tt neqns} variables are iterated --- the
values of the remaining {\tt (nvar-neqns)} variables are left alone. If the
run is an optimising case, then all the active iteration variables are
adjusted so as to find the minimum (or maximum) value of a parameter (the {\em
figure of merit}) in the {\tt nvar}-dimensional space of the problem.

All the iteration variables are constrained to lie between lower and upper
bounds, stored in arrays {\tt boundl} and {\tt boundu}, respectively, in input
block {\tt INPT1}. For instance, the plasma electron density is, by default,
confined to lie between the values $10^{19}$~m$^{-3}$ and
$10^{21}$~m$^{-3}$. Of course, it can also be constrained to lie below the
{\em calculated}\/ density limit, if constraint equation 5 is activated and
the f-value {\tt fdene} (iteration variable no.\ 9) is bounded by the values 0
and 1.

It is important to remember that iteration variables {\em must never be
initialised to zero}. The code will not be able to adjust the variable's value
if this is done, and it will stop with an error message.

\input{table_vars} % Table summarising iteration variables

\subsection{Figures of Merit}
\label{sec:foms}

In optimisation mode, \PS finds the self-consistent set of iteration variable
values that maximises or minimises a certain function of them, known as the
{\em figure of merit}. Several possible figures of merit are available, all of
which are formulated in routine {\tt FUNFOM} in source file {\tt optimiz.f}.
Switch {\tt minmax} in input block {\tt INPT1} is used to control which figure
of merit is to be used, as summarised in Table~\ref{tab:foms}. If the figure
of merit is to be minimised, {\tt minmax} should be positive, and if a
maximised figure of merit is desired, {\tt minmax} should be negative.

\input{table_foms} % Table summarising figures of merit

\subsection{Scanning Variables}
\label{sec:scans}

One of a number of variables can be scanned during the course of a \PS run.
This option provides a method of determining the sensitivity of the results to
different input assumptions. The user specifies which variable is to be
scanned (see Table~\ref{tab:scans}) and its required value at each point in
the scan. The scanned variable is defined by the value of {\tt nsweep} in
input block {\tt SWEP}, and this variable's values during the scan are set in
array {\tt sweep}, also in input block {\tt SWEP}.

Runs involving scans of this kind can only be performed in optimisation mode.
The results from the previous scan point are used as the input to the next
scan point. Routine {\tt SCAN} in source file {\tt aamain.f} stores many of
the output quantities in a separate output file (\texttt{PLOT}) for use with a
plotting program.

Scanning of derived quantities requires use of the appropriate constraint
equations. For instance, if the net electric power is scanned, constraint
equation~16 should be employed.

For obvious reasons, the active scanning variable must not also be an active
iteration variable.

\input{table_scans} % Table summarising scan variables

\section{The Input File}
\label{sec:infile}

The input file \texttt{IN} is used to change the values of the physics,
engineering and other code parameters from their default values, and to set up
the numerics (constraint equations, iteration variables etc.) required to
define the problem to be solved.

\subsection{Tokamak, Stellarator or RFP?}

In addition to the main input file \texttt{IN}, a second input file
\texttt{device.dat} is used to signal to the code whether a tokamak,
stellarator or reversed field pinch is to be modelled. (If the file does not
exist in the working directory, the standard tokamak model is used.)

File \texttt{device.dat} should contain a single character in the first
row, which is interpreted as follows:
\begin{tabbing}
\hspace{15mm}\= \texttt{0} : use tokamak model \\
\> \texttt{1} : use stellarator model \\
\> \texttt{2} : use reversed field pinch model
\end{tabbing}

\subsection{File Structure}

The input file is divided into {\it input blocks}\/ pertaining to the modular
structure of \PS itself. Each \INCLUDE file has a corresponding input block,
as shown in Table~\ref{tab:includes}.

This file structure is derived from that used in an old version of
\PSC which used the {\tt NAMELIST} method to read in data. This has
now been superseded by \FTSS standard routines, which also allow a great deal
of error-trapping to be carried out at the input stage.  All input data are
now screened for non-sensible values. This is a necessary addition to the
code, since UNIX workstation systems using RISC processors are notorious at
not terminating programs when an arithmetically impossible or undefined
operation (``{\tt NaN}'' error) is encountered.

\subsection{Format Rules}

The following rules must be obeyed when writing an input file:

\begin{enumerate}
\item
Each input block must start with the block name preceded by a dollar sign
({\tt \$}), and end with a {\tt \$END} statement.
\item
Each variable must be on a separate line, within the correct input block.
\item
There should be no leading spaces before the variable name, input block name
or {\tt \$END} statement.%%$
\item
Variable names, input block names and {\tt \$END} statements can be upper %%$
case, lower case, or a mixture of both.
\item
Spaces may not appear within a variable name or data value.
\item
Other spaces within a line, and trailing spaces, are ignored.
\item
Commas are not necessary between variables.
\item
Data can extend over more than one line.
\item
One-dimensional arrays can be explicitly subscripted, or unscripted, in which
case the following element order is assumed: {\tt A(1), A(2), A(3),...}
\item
At present, multiple dimension arrays can only be handled without reference to
explicit subscripts, in which case the following element order is assumed:
{\tt B(1,1), B(2,1), B(3,1),...} The use of the input file to specify multiple
dimension array elements is prone to error.
\item
Unscripted array elements must be separated by commas.
\item
Blank lines are allowed anywhere in the input file.
\item
Lines starting with a {\tt *} are assumed to be comments.
\item
Comment lines starting with five or more asterisks (i.e.\ {\tt *****}) are
reproduced verbatim in the output file. These should be used copiously to give
a great deal of information about the run being performed, and should be
updated before every single run of the code, as it is very easy to lose track
of what is being attempted.
\end{enumerate}

It is good practice to include all the input blocks in the input file, even if
none of the variables in some of them need changing. In this case, the {\tt
\$END}
%%$
 statement should immediately follow (on the next line) the input block
name statement, or a variable should be added in the usual way, but given its
default value as set in routine {\tt INITIAL}.

The following is a valid input block in the input file (the vertical lines
are simply to help show the column alignment):
\begin{center}
\begin{tabular}{||l}
$\!\!$\tt * This line is a comment that will not appear in the output \\
$\!\!$\tt ***** This line is a comment that will appear in the output \\
$\!\!$\tt \$inpt1                      \\ %%$
$\!\!$\tt boundl(1) = 2.5,             \\
$\!\!$\tt BOUNDU(10) = 3.,             \\
$\!\!$\tt BOUNDU(45) = 1,              \\
$\!\!$\tt * Another comment... Note that real values can be entered as if \\
$\!\!$\tt * they were integers, but NOT vice versa. \\
$\!\!$\tt epsfcn = 10.e-4,             \\
$\!\!$\tt Ftol = 1.D-4,                \\
$\!\!$\tt ICC =   2, 10, 11, 24, 31    \\
$\!\!$\tt ixc =   10, 12, 3, 36, 48,   \\
$\!\!$\hspace{15mm}\tt 1, 2, 6, 13, 16,\\
$\!\!$\tt IOPTIMZ = 1,                 \\
$\!\!$\tt maxcal = 200                 \\
$\!\!$\tt NEQNS = 5,                   \\
$\!\!$\tt NVAR = 10,                   \\
$\!\!$\tt \$END                        \\  %%$
\end{tabular}
\end{center}

The following are {\em invalid}\/ entries in the input file:
\begin{center}
\begin{tabular}{||l}
$\:$\tt \$inpt1                          \\ %%$
$\!\!$\tt boundl(1,1) = 2.5,             \\
$\!\!$\tt BOUNDU(N) = 3.,                \\
$\!\!$\tt A line of `random' characters like this will clearly wreak havoc\\
$\:$\tt * This is a comment with the asterisk not in the first column\\
$\!\!$\tt eps fcn = 10.e-4, ftol = 1.D-4 \\
$\!\!$\tt epsvmc = 1.0 e-4               \\
$\:$\tt maxcal = 200                     \\
$\!\!$\tt ICC =   2  10  11  24  31      \\
$\!\!$\tt IOPTIMZ = 1.0,                 \\
$\:$\tt \$END                            \\ %%$
\end{tabular}
\end{center}

\section{The Output File}

The output from the code is sent to file \texttt{OUT} in the working
directory.

\section{Running the Code}

This section will attempt to guide the user through the actual running of the
code in its various modes. In most cases only minor changes to the input file
are necessary to change the code's mode of operation --- usually the physics
and engineering variables, etc.\ remain unchanged, with the major differences
occurring in the numerical input only.

\subsection{Non-optimisation Mode}

Non-optimisation mode is used to perform benchmark comparisons, whereby the
machine size, output power etc.\ are known and one only wishes to find the
calculated stresses, beta values and fusion powers, for example. When starting
to model a new machine, \PS should always be run first in non-optimisation
mode, before any attempt is made to optimise the machine's parameters.

The first thing to do is to add to the input file all the known details about
the machine to be modelled. This may include some or all of the following:
\begin{itemize}
\item machine build (input block {\tt BLD})
\item aspect ratio (input block {\tt PHYDAT})
\item PF coil locations (input block {\tt PFC})
\item type of current drive to be used (input block {\tt CDDAT})
\item net electric power (input block {\tt INEQDAT})
\item various physics parameters (input block {\tt PHYDAT}), e.g.
\begin{itemize}
\item toroidal field on axis
\item electron density
\item electron temperature
\item elongation
\item triangularity
\item Troyon $g$ coefficient
\item edge safety factor
\end{itemize}
\end{itemize}

In addition, some of the switch values summarised in Chapter~\ref{chap:models}
may have to be altered from their default values.

Next, the relevant numerics information must be entered. Switch {\tt ioptimz}
in input block {\tt INPT1} must be set to {\tt -1} for non-optimisation
mode. Then the user must decide which constraint equations and iteration
variables to activate --- this choice is dictated partly by the information
required by the user, and partly by the machine being modelled itself.

As stated earlier, all the relevant consistency equations must be activated,
together with the corresponding iteration variables. A number of limit
equations can also be activated, to investigate how the calculated values
compare with the physics or engineering limits.  The following is part of an
example non-optimisation input file:
\begin{verbatim}
$INPT1
IOPTIMZ = -1
NEQNS = 8
NVAR = 8
ICC =  1,  2, 10, 11,  7, 16,  5, 24,
IXC =  5, 10, 12, 29,  7,      9, 36, 4,
$END

$INEQDAT
FPNETEL = 1.0
PNETELIN = 1200.0
$END
\end{verbatim}
\vspace{-8mm}
$\vdots$

Consistency equations 1, 2, 10, 11 and 7 are activated, together with limit
equations~16, 5 and 24. This example assumes that neutral beam current drive
is present (equation~7 with variable~7), and that the net electric power is to
be fixed at 1200~MW\@. Note the practice of vertically aligning corresponding
equations and variables --- constraint equation~16 has no corresponding
iteration variable (which would normally be no.\ 25, {\tt fpnetel}), as we
want the net electric power to be fixed at the value given by {\tt
pnetelin}. Since in non-optimisation mode, the number of variables must be
equal to the number of equations, we have scope to add a ``free'' iteration
variable, in this case no.\ 4 --- electron temperature, to help raise the
fusion power sufficiently to obtain the required net electric power. Finally,
note the use of the density and Troyon beta limit equations; the values of the
corresponding f-values will indicate if the limits are exceeded and by how
much.

On running \PS and (hopefully) achieving a feasible result, examination of the
output may well show up discrepancies between some of the parameter values
produced and their known values (if available). Remember that, of all the
variables shown in the variable descriptor file with a default value, only
those declared as {\em active iteration variables}\/ can change from their
initial values, whether they are set in the input file or in the
initialisation routine {\tt INITIAL}. However some of the calculated
parameters may be wrong, the most common of which are as follows:
\begin{itemize}
\item
Plasma current. This can be adjusted using the edge safety factor {\tt q} in
input block {\tt PHYDAT}: $I_p \propto 1/q$
\item
Fusion power. This scales roughly with the density profile factor {\tt alphan}
in input block {\tt PHYDAT}.
\item
Build parameters. It may be necessary to change non-critical thicknesses to
achieve the correct machine build.
\end{itemize}
It may still be difficult, if not impossible, to reconcile the fusion power
and the net electric power with the required values. This may well be due to
the power conversion efficiency values being used --- refer to
Figure~\ref{fig:pwrconv}.

With luck, a few iterations of this process will produce an adequate benchmark
case. A typical input file for use with \PS in non-optimisation mode is
contained in Appendix~\ref{app:infile1}.

\subsection{Optimisation Mode}
\label{sec:optim}
Running \PS in optimisation mode requires few changes to be made to the input
file from the non-optimisation case, except in input blocks {\tt INPT1}, {\tt
INEQDAT} and {\tt SWEP} --- the blocks associated with the numerics of the
problem. The main differences between optimisation mode and non-optimisation
mode are:
\begin{enumerate}
\item
Optimisation mode applies lower and upper bounds to all active iteration
variables.
\item
There is no upper limit to the number of active iteration variables in
optimisation mode.
\item
A figure of merit must be specified in optimisation mode.
\item
Scans can be performed in optimisation mode.
\end{enumerate}

Switch {\tt ioptimz} in input block {\tt INPT1} must be set to {\tt 1} for
optimisation mode. As before, the user must decide which constraint equations
and iteration variables to activate. Again, the choice depends largely on the
information required by the user and the extent of the freedom that the code
may have with the machine's parameters.

The following is part of an example optimisation input file:
\begin{verbatim}
$INPT1
IOPTIMZ = 1
NEQNS = 16
NVAR = 19
ICC =  1,  2, 10, 11,  7, 16,  5, 24, 14,  8, 31, 32, 33, 34, 35, 36,
IXC =  5, 10, 12, 29,  7,      9, 36, 19, 14, 48, 49, 50, 51, 53, 54,
4, 6, 1, 18,
BOUNDL(1) = 2.5
BOUNDU(10) = 2.0
MINMAX = 6
$END

$INEQDAT
FPNETEL = 1.0
PNETELIN = 1200.0
WALALW = 4.4
$END

$SWEP
ISWEEP = 3
NSWEEP = 11
SWEEP = 3.5, 3.7, 3.9
$END
\end{verbatim}
\vspace{-8mm}
$\vdots$

The figure of merit in this example is the (minimum) cost of electricity ({\tt
minmax = 6}). Note that additional limit equations are now active, along with
a second consistency equation related to the neutral beam current drive ---
the number of decay lengths to the plasma centre is constrained to be equal to
the input value ({\tt tbeamin} in input block {\tt CDDAT}, which is not shown
here).  Furthermore, there are now more iteration variables than constraint
equations, to aid the minimisation process.  Finally, note that a three-point
scan in the Troyon $g$ coefficient {\tt dnbeta} --- scanning variable~11, is
to be performed.

A useful practice in optimisation mode is to perform ``stationary'' scans,
whereby the same value is given to the scanning variable on successive
iterations. This provides a check as to how well converged the solution has
become. If scans of a given variable are to be made over a large range of
values, it is often a good idea to start the scan in the middle of the desired
range, and to split the scan in two --- one going downwards from the initial
value, and the other upwards.  This ensures that the whole range of the scan
produces well-converged machines (assuming a ``good'' initial point), without
sharp changes in gradient in the parameter values.

It should be remembered that the value of the scan variable is set in the
array {\tt sweep}, and this overrules any value set for the variable elsewhere
in the input file. For instance, in the example above, the values of {\tt
dnbeta} set in the {\tt sweep} array would overrule any value for {\tt dnbeta}
set in the {\tt PHYDAT} input block.

The output from an optimisation run contains an indication as to which
iteration variables lie at their limiting values. On the whole there is a
greater chance of unfeasible solutions being found whilst in optimisation
mode, and Section~\ref{sec:problems} will hopefully be of some use in this
situation. A typical input file for use with \PS in optimisation mode is
contained in Appendix~\ref{app:infile2}.

\section{Problem Solving}
\label{sec:problems}

Experience has shown that the first few attempts at running \PS with a new
input file tends to produce unfeasible results --- that is, the code will not
find a consistent set of machine parameters. The highly non-linear nature of
the numerics of \PS is the reason for this difficulty, and it often requires a
great deal of painstaking adjustment of the input file to overcome.

\subsection{General Problems}

A code of the size and complexity of \PS contains myriads of equations and
variables. Virtually everything depends indirectly on everything else because
of the nature of the code structure, so perhaps it is not surprising that it
is often difficult to achieve a successful outcome.

Naturally, problems will occur if some of the parameters become unphysical.
For example, if the aspect ratio becomes less than or equal to one, then we
must expect problems to appear. For this reason, the bounds on the iteration
variables and the allowed ranges of all the input variables have been selected
with great care.

The code contains a large (though probably not exhaustive) number of error
traps to try and prevent problems from propagating. These include tests for
unphysical values, and checks to prevent divisions by zero, and non-sensible
arguments for logarithms and square roots, etc. However, occasionally
arithmetic (``{\tt NaN}'') errors still occur, although their incidence is
low. They now usually only occur due to unfeasibility problems (see later).

The error messages produced by the code attempt to provide diagnostic
information, telling the user where the problem occurs, and also suggest a
possible solution. These messages are out of necessity brief, and so cannot
promise to lead to a more successful outcome.

\subsection{Optimisation Problems}

On reflection it is perhaps surprising that \PS ever does manage to find the
global minimum figure of merit value, since if there are {\tt nvar} iteration
variables active the search is over {\tt nvar}-dimensional parameter space, in
which there may be many shallow minima of approximately equal depth. Remember
that {\tt nvar} is usually of the order of twenty.

The machine found by \PS may not, therefore, be the absolutely optimal
device. It is quite easy to have two or more solutions, with results only a
few per cent different, but a long way apart in parameter space. The technique
of ``stationary'' scans described in Section~\ref{sec:optim} above can often
help in this situation, which is why this method is recommended at all times.

Scans should be started in the middle of a range of values, to try to keep the
scan within the same family of machines. The optimum machine found may
otherwise suddenly jump to a new region of parameter space, causing the output
variables to seem to vary unpredictably with the scanning variable.

It should be noted that in general the machine produced by \PS will always sit
against one or more operation limits. If, during a scan, the limit being leant
upon changes (i.e.\ if the machine jumps from leaning on the beta limit to
leaning on the density limit) the output parameters may well become
discontinuous in gradient, and trends may suddenly change direction.

\subsection{Unfeasible Results}

In the numerics section of the output file, the code indicates whether the run
produced a feasible or unfeasible result. The former implies a successful
outcome. An unfeasible result, however, occurs if \PS cannot find a set of
values for the iteration variables which satisfies all the given
constraints. In this case, the values of the constraint residues shown in the
output give some indication of which constraint equations are not being
satisfied --- those with the highest residues should be examined further. In
optimisation mode, the code also indicates which iteration variables lie at
the edge of their allowed range.

Unfeasible runs are caused either by ill-defining the problem to be solved, or
by starting the problem in an unfavourable region of parameter space. The
latter can be checked simply by changing the initial values of the {\em
active}\/ iteration variables in the input file, but the former requires some
extra work. This situation arises if there are insufficient iteration
variables for the given constraint equations. It is important to choose the
right number of {\em useful}\/ iteration variables for the problem to be
solved --- it is possible to activate too many iteration variables as well as
too few, some of which may be redundant.

A technique that occasionally removes problems due to unfeasible results,
particularly if an error code {\tt ifail=3} is encountered during an
optimisation run, is to adjust slightly one of the limits imposed on the
iteration variables, even if the limit in question has not been reached. This
subtly alters the gradients computed by the code during the iteration process,
and may tip the balance so that the code decides that the device produced is
feasible after all. For instance, a certain component's temperature might be
400~K, and its maximum allowable temperature is 1000~K\@. Adjusting this limit
to 900~K (which will make no difference to the {\em actual}\/ temperature) may
be enough to persuade the code that it has found a feasible solution.

Similarly, the order in which the constraint equations and iteration variables
are stored in the {\tt icc} and {\tt ixc} arrays can make the difference
between a feasible and unfeasible result. This seemingly illogical behaviour
is, sadly, typical of the way in which the code works.

Unfeasible cases often produce unrealistic machines, so one should not believe
the output values from these runs. Unfortunately, the stationary scan method
sometimes, though not always, fails to help these cases, since it will tend to
keep starting the run at the same point. Ill-defined problems sometimes
produce arithmetic errors, for obscure reasons.

Though a great deal of work has been performed on the code to improve its
standard, there can be no guarantee that \PS is entirely bug-free, simply
because of its large size. Rarely, then, it may be that an unfeasible result
indicates that the code has encountered a programming error, although its
precise location will be almost impossible to find by simply examining the
output file.

It may be the case that the act of satisfying all the required constraints is
impossible. No machine can exist if the allowed operating regime is too
restrictive, or if two constraint equations require conflicting parameter
spaces. In this case some relaxation of the requirements is needed for the
code to produce a successful machine design.

\subsection{Hints}

The above sections should indicate that it is the complex interplay between
the constraint equations and the iteration variables that determines whether
the code will be successful at producing a useful result. It can be a somewhat
laborious process to arrive at a working case, and (unfortunately, perhaps)
experience is often of great value in this situation.

It should be remembered that sufficient iteration variables should be used to
solve each constraint equation. For instance, a particular limit equation may
be $A \leq B$, i.e.\ $A = fB$, where the f-value $f$ must lie between zero and
one for the relation to be satisfied.  However, if none of the iteration
variables have any effect on the values of $A$ and $B$, and $A$ happens to be
{\em greater}\/ than $B$, then \PS will clearly not be able to solve the
constraint.

The lower and upper bounds of the iteration variables are all available to be
changed in the input file. Constraints can be relaxed in a controlled manner
by moving these bounds, although in some cases care should be taken to ensure
that unphysical values cannot occur.  The code indicates which iteration
variables lie at the edge of their range.

It is suggested that constraint equations should be added one at a time, with
sufficient new iteration variables activated at each step.  If the situation
becomes unfeasible it can be helpful to reset the initial iteration variable
values to those shown in the output from a previous feasible case, and rerun
the code.

Finally, it should be borne in mind that the machine that is envisaged may not
be a valid solution to the constraints being imposed, no matter how many
degrees of freedom (i.e.\ iteration variables) are available. In this case,
and many others, the user has to relax the constraints slowly until a feasible
result is found.
