\documentclass[11pt,a4paper]{article}
\usepackage{epsfig,colordvi,latexsym}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{color}
\usepackage{tikz}  %  for VMCON flowchart in Appendix A
\usepackage{url}
\usepackage{hyperref}
\usepackage{framed}
\usepackage{color}
\usepackage{mdframed}

\definecolor{codeColour}{HTML}{F7F9FA}
\definecolor{codeLine}{HTML}{E6E8EB}
\mdfsetup{backgroundcolor=codeColour,  linecolor=codeLine,
linewidth=3pt, topline=false, bottomline=false, rightline=false,
innertopmargin=15pt, innerbottommargin=5pt}

\usetikzlibrary{trees}

\pretolerance=10000
\topmargin=0mm
\headheight=0mm
\headsep=8mm
\textwidth=170mm
\textheight=240mm
\footskip=10mm
\oddsidemargin=0mm
\evensidemargin=-12mm
\parskip=2mm
\parindent=0mm

\setcounter{secnumdepth}{3}
\newcommand{\indat}{\mbox{\texttt{IN.DAT}}}
\newcommand{\mfile}{\mbox{\texttt{MFILE.DAT}}}
\newcommand{\outdat}{\mbox{\texttt{OUT.DAT}}}
\newcommand{\plotdat}{\mbox{\texttt{PLOT.DAT}}}
\newcommand{\process}{\mbox{\texttt{PROCESS}}}
\newcommand{\vmcon}{\mbox{\texttt{VMCON}}}
\renewcommand{\vec}[1]{\boldsymbol{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Add here the date of the latest change and the code revision number
\newcommand{\version}{
19 April 2018
\hfill
PROCESS version: 1.0.13
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\setheader}[1]
 {\markright{\rlap{\lower0.8ex\hbox to\textwidth{\hrulefill}}{\bf#1}}}
\newcommand{\mychapter}[1]{\small\normalsize
 \setcounter{footnote}{0}
 \chapter{#1}
 \pagestyle{myheadings}
 \setheader{Chapter \thechapter\hspace{0.8em}#1}}
\newcommand{\myappendix}[1]{\small\normalsize
 \setcounter{footnote}{0}
 \chapter{#1}
 \pagestyle{myheadings}
 \setheader{Appendix \thechapter\hspace{0.8em}#1}}

\begin{document}

\footnotesize
\hfill

\vspace*{4cm}
\begin{center}
\Huge A guide to the utilities of the \\ PROCESS Fusion Reactor Systems Code\\
~\\ \LARGE The PROCESS Team: P.\ J.\ Knight, M.\ D.\ Kovari, H.\ Lux, J.\ Morris, S.\ I.\ Muldrew \\
~\\ \Large Culham Centre for Fusion Energy/ United Kingdom Atomic Energy Authority\\
Culham Science Centre, Abingdon, Oxon, OX14 3DB, UK
\end{center}

\normalsize
A number of utilities for \process\ are available, for instance to modify the
input file \indat, run \process\ until a feasible solution is found, or to
extract and plot data from the \process\ output. All utilities are available
from \texttt{~PROCESS/master/utilities} where also example config files are kept.

For \process\ \textit{users}, only the executables described in
Section~\ref{sec:py_exec} are relevant. For anyone interested in modifying the
existing code or developing new utilities the \process\ Python
libraries are described in Section~\ref{sec:py_lib}.

All executables use Python library functions either from the publicly
available \texttt{numpy}, \texttt{scipy} and \texttt{matplotlib} libraries or
the \process\ Python libraries documented in Section~\ref{sec:py_lib}. To use
the \process\ Python libraries you need to make sure their directory is in
your Python path. Use the commands given in the \process\/ Userguide to
do this.

All Python code has been written for Python 3.

\vfill
\footnotesize
\version
\normalsize

\tableofcontents

\newpage

\section{Executables}
\label{sec:py_exec}

All executables can be run by using any of the following commands:
\begin{quote}
\begin{verbatim}
python executable_name.py
python3 executable_name.py
executable_name.py
\end{verbatim}
\end{quote}
and they typically have a short description of their usage when putting
\texttt{-h} or \texttt{--help} as arguments:
\begin{quote}
\begin{verbatim}
executable_name.py -h
\end{verbatim}
\end{quote}

Some executables come with a configuration file that typically follows the
naming convention \texttt{executable\_name.conf}. To run the executable please
copy the config file into your own work directory. Do \textbf{NOT} edit
the config file in the \process\ directory.

Due to the large amount of existing utilities, we have grouped them in sections below.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Running PROCESS}

%-------------------------------
\subsubsection{Randomly vary the starting point (run\_process.py)}
\label{subsec:run_process}
This program runs \process\ many times, randomly varying the initial values of the iteration variables until a feasible solution is found.  Stops when a feasible solution is found.  If in the course of a scan some scan points result in feasible solutions and some do not, \texttt{run\_process.py} will stop if and only if the number of unfeasible scan points is less than or equal to the parameter \texttt{NO\_ALLOWED\_UNFEASIBLE}.

\begin{description}
\item{\textbf{Input:}}
\texttt{run\_process.conf} (optional), \indat\

\item{\textbf{Output:}} A directory is created for each run. containing all the standard
  PROCESS output, \texttt{process.log} (log file), and \texttt{README.txt}
  (contains comments from config file)
\end{description}

\paragraph{Configuration Options:}

The configuration file \texttt{run\_process.conf} has the following style:
\begin{framed}
\begin{verbatim}
* This is a comment in the config file!

* Path to working directory in which PROCESS is run.
WDIR = Run1
* original IN.DAT name
ORIGINAL_IN_DAT = demo1a_10_sep_13.IN.DAT
* PATH to PROCESS binary
PROCESS = ~PROCESS/master/process
* ONE line comment to be put into README.txt
COMMENT = This is a test DEMO run! ;-)
* Maximum number of PROCESS runs
NITER = 5
* integer seed for random number generator; use None for random seed
SEED = 2
* factor within which the iteration variables are changed
FACTOR = 1.5
* Number of allowed unfeasible points that do not trigger rerunning.
NO_ALLOWED_UNFEASIBLE = 0
* include a summary file with the iteration variables at each stage.
INCLUDE_ITERVAR_DIFF = True
* add iteration variables - comma separated
ADD_IXC = 99, 77
* remove iteration variables - comma separated
DEL_IXC =
* add constraint equations  - comma separated
ADD_ICC = 57,
* remove constraint equations - comma separated
DEL_ICC =
* set any variable to a new value
* the variable does not have to exist in IN.DAT
VAR_TFTORT = 1.9
VAR_EPSVMC = 1e-4
* remove variables
DEL_VAR_IITER
\end{verbatim}
\end{framed}
A configuration file with an alternative name can be specified using the optional argument
\begin{quote}
\begin{verbatim}
run_process.py -f CONFIGFILE
\end{verbatim}
\end{quote}



%-------------------------------
\subsubsection{List \process\ runs with comments (build\_index.py)}

Creates an index of all \process\ run comments, after they have been created by \texttt{run\_process} in a series of subfolders.

\begin{description}
\item{\textbf{Input:}}
README.txt files in subfolders

\item{\textbf{Output:}}
\verb|Index.txt|
\end{description}

\paragraph{Configuration Options:}

Optional arguments are:
\begin{quote}
\begin{verbatim}
# change the name of the file containing the folder description
build_index.py -r README.txt
# append the results to Index.txt instead of creating a new file
build_index.py -m a
# change the name of the subfolder Base - default=Run
build_index.py -b Base
# give a list of subfolder suffixes - default=all
build_index.py -s 1-4,6,8,9-12
# increase verbosity
build_index.py -v
\end{verbatim}
\end{quote}

An example \texttt{Index.txt} file might look like this
\begin{framed}
\begin{verbatim}
Run1:
 Original run

Run2:
 Changed the no. TF coils
...
\end{verbatim}
\end{framed}


%-------------------------------
\subsubsection{Test the solver accuracy and globality (test\_process.py)}

This program has a similar structure to the \texttt{run\_process.py} program, but varies the iteration variable start parameters for as many iterations as requested by the configuration file. It outputs a summary of the final iteration parameter values and figure of merit values for testing the accuracy of the optimisation solver in PROCESS. This also allows the user to verify that the final solution is not only a local solution. For this type of study a large value of the factor within which the iteration variables are changed should be chosen!

\begin{description}
\item{\textbf{Input:}}
\texttt{test\_process.conf}, an \indat\ file as specified in the config file

\item{\textbf{Output:}} All the standard
  PROCESS output, \texttt{process.log}, \texttt{README.txt}, \texttt{time.info} (stores the run time of actual PROCESS iterations), \texttt{SolverTest.out}
\end{description}
The \texttt{SolverTest.out} file contains a table of the \texttt{ifail} values (see Userguide), the figure of merit, the square root of the sum of the squares of the individual constraints as well as the initial and final values for the iteration variables and the individual constraint residuals. The value of Q, i.e. the ratio of
fusion power to injected power, is also included in the SolverTest.out file. All values can be used to diagnose the performance of the optimisation solver.


\paragraph{Configuration Options:}

The configuration file \texttt{test\_process.conf} has the following style:
\begin{framed}
\begin{verbatim}
* No iterations
NITER = 1000

* Working directory: Subdirectory in which to copy IN.DAT and test_process.conf
WDIR=Run1/

* original IN.DAT name (should not be called IN.DAT!)
ORIGINAL_IN_DAT = minimal_demo2_nosweep.IN.DAT

* sets flag of same name in IN.DAT:
*     None - keeps original value
*     -1   - Non-optimisation only
*      0   - one non-optimisation step followed by optimised iteration
*      1   - optimisation only
IOPTIMZ = 1

* sets the error tolerance for VMCON
*     None - keeps the original value (IN.DAT or default)
EPSVMC = None

* sets the step length for the finite difference derivatives
*     None - keeps the original value (IN.DAT or default)
EPSFCN = None


*sets the figure of merit
*positive value - minimise, negative value - maximise
*     None  - keeps the original value
*     1     - plasma major radius
*     6	    - cost of electricity
MINMAX = None

* integer seed for random number generator; use None for random seed
SEED = 2

* factor within which the iteration variables are changed
FACTOR = 1.1

* PATH to PROCESS binary
PROCESS=process.exe
\end{verbatim}
\end{framed}

A configuration file with an alternative name can be specified using the optional argument
\begin{quote}
\begin{verbatim}
test_process.py -f CONFIGFILE
\end{verbatim}
\end{quote}


%--------------------------------------------------------
\subsubsection{Step from one model to another (a\_to\_b.py)}
\label{sec:atob}

When attempting to model a reactor very different from those in previous studies, it can be difficult to find a feasible solution.  This utility takes an initial \indat\ (\texttt{A.DAT}) that is known to run successfully, and a target \indat\ (\texttt{B.DAT}) that is substantially different.  The difference is broken into small steps, and \process\ runs repeatedly, stepping from the initial input file to the target input file.  After each step, the output values of the iteration variables are used as the input starting values for the next step.

\begin{description}
\item{\textbf{Input:}}
\texttt{a\_to\_b.conf}, \texttt{A.DAT} and its corresponding \texttt{MFILE.DAT}, \texttt{B.DAT}.
(These names can be changed by the user.)

\item{\textbf{Output}}

When the program finishes, the .DAT files from the last run of \process\ can
be found in the specified working directory.

If option keep\_output = True, then \indat, \outdat, \mfile\ and logged \process\
output of each step are stored. Files are prefaced with their step number
eg. \texttt{003.IN.DAT} and copied to the specified output directory.

\item{\textbf{Troubleshooting}}

Ensure that each relevant variable is only listed once in the vardes.html file.

\end{description}

\paragraph{Configuration Options:}

The configuration file \texttt{a\_to\_b.conf} has the following style:
\begin{framed}
\begin{verbatim}
*Comment line

*Working directory to store temporary files, default = wdir
wdir = wdir

*Switch to keep .DAT files for every step, default = True
keep_output = True

*Directory for output if keep_output = True, default = steps
outdir = steps

*IN.DAT file for A, default = A.DAT
a_filename = A.DAT

*IN.DAT file for B, default = B.DAT
b_filename = B.DAT

*Path to process binary
path_to_process = /home/PROCESS/master/process

*Number of iterations of vary_iteration_variables to run, default = 20
vary_niter = 20

*Number of steps to go from A to B, default = 10
nsteps = 10

*Factor to vary iteration variables within, default = 1.2
factor = 1.2

*Gap between upper and lower bounds to narrow to, default = 1.001
bound_gap = 1.001
\end{verbatim}
\end{framed}



%-----------------------------------
\subsubsection{N-Dimensional Scanner Utility}

This suite of Python utilities allows the user to conduct systematic, multi-dimensional parameter studies with \process. It systematically varies a set of N user defined parameters within predefined bounds. The final results can be evaluated using the corresponding visualisation tool and/or saved in standard NetCDF format for further analysis.

The suite contains the following executables
\begin{itemize}
\item \texttt{ndscan.py} - executes the Nd-scan as specified in the configuration file.
\item \texttt{ndscan\_package\_only.py} - creates a NetCDF output file from a previous Nd-scan run.
\item \texttt{ndscan\_and\_package.py} - both executes the Nd-scan and creates the NetCDF output file.
\item \texttt{ndscan\_visualisation.py} - visualises the NetCDF output.
\end{itemize}


\begin{description}
\item{\textbf{Input:}}
 \texttt{ndscan.json}, \indat

\item{\textbf{Output:}} All MFILES in subdirectory \texttt{MFILES}, packaged NetCDF output file as named in configuration file (default ``NdscanOutput.nc'').
\end{description}

When running any of the ndscan tools, optional arguments are:
\begin{quote}
\begin{verbatim}
#to specify another location/name for the configfile
ndscan.py -f CONFIGFILE

Use -h or --help for help
\end{verbatim}
\end{quote}
For the visualisation tool the corresponding NetCDF input file can also be specified with \texttt{-f}. Per default ``NdscanOutput.nc'' is used.

\paragraph{Configuration Options:}

The configuration file \texttt{ndscan.json} uses the JSON format\footnote{www.json.org} and has the following style
\begin{framed}
\begin{verbatim}
{
    "axes": [
	{
            "lowerbound": 7.5,
            "steps": 16,
            "upperbound": 9.0,
            "varname": "rmajor"
        },
        {
            "lowerbound": 5.5,
            "steps": 16,
            "upperbound": 7.0,
            "varname": "bt"
        }
    ],
    "_comment": [
        "This field helps to describe the config file for users reading",
        "Anything you write in here will be ignored by the code",
        "Each axis has these configuration parameters available:",
        "varname",
        "lowerbound",
        "upperbound",
        "'steps': number of evaluations"
    ],
    "optionals": {
        "remove_scanvars_from_ixc": true,
        "smooth_itervars": true
    },
    "description": "Description of the goals of this specific run",
    "title": "NdscanOutput",
    "author": "Me",
    "output_vars": [
        "beta",
        "pheat",
        "powfmw",
        "pradmw",
        "powerht",
        "cirpowfr",
        "te",
        "hfact",
        "dnelimt",
        "dene",
        "rmajor",
        "bt",
        "pnetelmw",
        "coe",
        "fwbllife",
        "capcost",
        "palpmw",
        "wallmw",
        "taueff"
    ]
}
\end{verbatim}
\end{framed}
The only required input parameter in the configuration file are the scan axes, out of which at least one has to be specified. For each axis a \texttt{varname}, a \texttt{lowerbound}, an \texttt{upperbound} and the number of \texttt{steps} $>1$ have to be specified. All other parameters in the configuration file are optional. The parameters relevant for running the N-dimensional scan are:
\begin{description}
\item[\texttt{\_comment}] Anything in the comment section (like all other undefined sections) is for the user only and will be ignored by the program.
\item[\texttt{optionals:remove\_scanvars\_from\_ixc}] Removes all scanning variables from the iteration variables of the IN.DAT file (default=True).
\item[\texttt{optionals:smooth\_itervars}] Ensures that each next point starts from the last successful run. This increases the run time, but improves convergence and reduces errors.
\end{description}
The parameters only relevant to the creation of the summary NetCDF file are:
\begin{description}
\item[\texttt{author}] The author will be copied into the NetCDF file.
\item[\texttt{description}] The description will be copied into the NetCDF file.
\item[\texttt{title}] Name of the output NetCDF file (default \texttt{NdscanOutput}) that is also copied into the title of the NetCDF file.
\item[\texttt{output\_vars}] The variables that will be extracted from the MFILEs and stored in the NetCDF file. (Only needed when creating the NetCDF output file.)
\end{description}
Additional parameters can be specified as in the \texttt{config} section for the \texttt{evalualte\_uncertainties.py} tool, see section \ref{subsec:evalunc}.

The resulting NetCDF file can be visualised using the \texttt{ndscan\_visualisation.py} tool. It has an interactive menu and is fairly self-explanatory.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Output Processing}

%-------------------------------
\subsubsection{Turn output into input (write\_new\_in\_dat.py)}

This program creates a new \indat\ file with the initial values of all the iteration variables replaced by their results in \outdat, if that ouput is a feasible solution.

When a scan has been run, by default this program uses the last feasible point in that scan to write the new starting values. There is also an option to select the first feasible solution from a scan.

\begin{description}
\item{\textbf{Input:}}
\indat, \mfile\

\item{\textbf{Output:}}
\texttt{new\_IN.DAT}
\end{description}

\begin{quote}
\begin{verbatim}
usage: write_new_in_dat.py [-h] [-f MFILE.DAT] [-i IN.DAT]

optional arguments:
  -h, --help   show this help message and exit
  -lfp         use the last feasible point from a scan (default)
  -ffp         use the first feasible point from a scan
\end{verbatim}
\end{quote}

%-------------------------------
\subsubsection{Create csv file summarising data in plot\_proc.py output (output\_data.py)}

A utility to output a set of data very similar to {\bf plot\_proc.py}, but to a comma-delimited format for inclusion in spreadsheets. This is used by \texttt{archive.sh} (see Section \ref{ssec:archive}) to import data into the \process\/ runs database. For other uses, it's best to use PLOT.DAT instead, as this is always generated by PROCESS, and can be easily loaded into a spreadsheet.
\begin{description}
\item{\textbf{Input:}}
 \mfile (or as specified by user)

\item{\textbf{Output:}}
\verb|process_summary.txt| (or as specified by user)
\end{description}

\paragraph{Configuration Options:}

Optional arguments are:
\begin{quote}
\begin{verbatim}
usage: output_data.py [-h] [-f FILENAME] [-o OUTPUT]

Produce a single-column comma-separated (.txt) summary for a given scan. For
info contact rich.kemp@ccfe.ac.uk or james.morris2@ccfe.ac.uk

optional arguments:
  -h, --help   show this help message and exit
  -f FILENAME  specify input filename
  -o OUTPUT    specify output filename
\end{verbatim}
\end{quote}

%--------------------------------------------------------
\subsubsection{Create csv file summarising data for database (create\_csv4database.py)}

This is essentially the same tool as \texttt{output\_data.py}, but the format is frozen to assure consistency for the PROCESS Runs database excel spreadsheet.


%--------------------------------------------------------
\subsubsection{Create archivable files for PROCESS Runs database (archive.sh)}
\label{ssec:archive}

This is a very simple shell script to create all the relevant files for the PROCESS Runs database on the EUROfusion IDM\footnote{https://idm.euro-fusion.org/?uid=2MUP64}. It uses the \verb|create\_csv4database.py| and the \verb|plot\_proc.py| utilities.

\begin{description}
\item{\textbf{Input:}}
\indat, \outdat, \mfile

\item{\textbf{Output:}}
\verb|PREFIX.|\indat, \verb|PREFIX.|\outdat, \verb|PREFIX.pdf|, \verb|PREFIX.csv|
\end{description}

The convention for the PREFIX is to use the following format e.g. DEMO1\_detailed\_description\_Year\_Month\_Day, where DEMO1 is the description of the design investigated and the detailed description summarises the key changes made to the design.



%------------------------------------------
\subsubsection{Compare a reference desing with a PROCESS run (ref\_check.py)}
Tool for comparing a PROCESS MFILE output file to a JSON reference file for a
certain type of machine.

The JSON file format contains two dictionaries: 'PARAMS' and 'LIMITS'.

Arguments\\
\texttt{-r        }     Reference JSON file\\
\texttt{-f        }     MFILE file to compare to JSON reference\\
\texttt{-s        }     Save output to file called input\_comp.txt\\

Below is an example of the JSON reference file. The PARAMS dictionary takes
just a variable name and the value it has for the reference. The LIMITS
dictionary takes the limit value name as the key. The content of the limit is
then the limit value, whether it is a minimum or maximum and then lastly the
paramter it is limiting. For more examples look at the cfetr\_small\_ref.json in
the test suite CFETR\_small case folder.

\begin{framed}
\begin{verbatim}
{
	"PARAMS":
        {
            "rmajor" : 5.7,
            "rminor": 1.6,
            "aspect": 3.563,
            "bt": 5.0,
            "kappa": 1.8,
            "triang": 0.4,
            "hfact": 1.3,
            "powfmw": 250
        },

    "LIMITS":
        {
            "alstrtf" :
                {
                    "limit": 600.0e6,
                    "type": "-",
                    "parameter": "strtf2"
                },
            "pseprmax" :
                {
                    "limit": 25.0,
                    "type": "-",
                    "parameter": "pdivt/rmajor"
                },
            "ripmax" :
               {
                   "limit": 0.5,
                    "type": "-",
                    "parameter": "ripple"
                }
        }
}
\end{verbatim}
\end{framed}

The code outputs the parameters which don't match, the parameters that match, the
lower limits that aren't satisfied, the lower limits that are satisfied, the upper
limits that aren't satisfied and the upper limits that are satisfied.

%---------------------------------------
\subsubsection{Compare two MFILEs (mfile\_comparison.py)}
Tool for comparing two MFILEs and outputting significant differences in numerical values.

Arguments\\
\texttt{-f        }     Files to compare\\
\texttt{-s        }     Save output to file called comp.txt\\
\texttt{--acc     }     Percentage difference threshold for reporting\\
\texttt{--verbose }     Additional output\\


%-----------------------------------------
\subsubsection{Compare two input files (in\_dat\_comparison.py)}
Tool for comparing two IN.DATs and outputting inputs in one file and not the other,
inputs in both with different values and inputs in both with the same value.

Arguments\\
\texttt{-f        }     Files to compare\\
\texttt{-s        }     Save output to file called input\_comp.txt\\


%-----------------------------------------
\subsubsection{Convert PROCESS MFILE to Catia CAD readable output (cad\_output.py)}

The PROCESS utility \texttt{cad\_output.py} takes the \texttt{mfile.py} and produces an 
output file suitable for using in CAD programs (for testing \emph{Catia} was used). The output 
file is named \texttt{PROCESS.CAD} by default. The output file provides a list of named 
parameters for input into \emph{Catia}. Modification for other CAD programs may be required. 
The options for the script are:\\

\begin{mdframed}
 \begin{verbatim}
  cad_output.py [-h] [-f FILENAME] [-o OUTPUT] [-s]

  Produce a CAD output file of the PROCESS MFILE file for a given scan. For info
  contact james.morris2@ccfe.ac.uk
  
  optional arguments:
    -h, --help   show this help message and exit
    -f FILENAME  specify input filename
    -o OUTPUT    specify output filename
    -s, --show   show plot as well as saving figure
 \end{verbatim}
\end{mdframed}

%-----------------------------------------
\subsubsection{Convert IN.DAT to new format (convert\_in\_dat.py)}

The utility \texttt{convert\_in\_dat.py} takes a old format \texttt{IN.DAT} ($\sim$pre-2014) 
and coverts it into the newer format. As fewer old \texttt{IN.DAT}s exist this utility will 
eventually be removed. The options for the script are:\\

\begin{mdframed}
 \begin{verbatim}
  convert_in_dat.py [-h] [-f f] [-o o]

  PROCESS IN.DAT converter. Convert IN.DAT into new format. For info contact
  james.morris2@ccfe.ac.uk

  optional arguments:
   -h, --help  show this help message and exit
   -f f        File to read as IN.DAT (default="IN.DAT")
   -o o        File to read as IN.DAT (default="new_IN.DAT")
 \end{verbatim}
\end{mdframed}

%-----------------------------------------
\subsubsection{Create MCNP input file from MFILE.DAT (mcnp\_output.py)}

The utility \texttt{mcnp\_output.py} takes a \texttt{MFILE.DAT} and converts it to a suitable 
format for MCNP runs. The options for the script are:\\

\begin{mdframed}
 \begin{verbatim}
  mcnp_output.py [-h] [-f f] [-o o] [--ctf]

  Process MFILE.DAT into PROCESS.MCNP file.

  optional arguments:
   -h, --help  show this help message and exit
   -f f        File to read as MFILE.DAT
   -o o        File to write as PROCESS.MCNP
   --ctf       True/False flag for CTF
 \end{verbatim}
\end{mdframed}

%-----------------------------------------
\subsubsection{Create a html output summary from MFILE.DAT (output\_summary.py)}

This utility has two versions in the repository:
\begin{itemize}
  \item \texttt{output\_summary.py} - general summary generate automatically. Not customisable.
  \item \texttt{output\_detailed.py} - takes a configuration file called 
  \texttt{output\_detailed.json} to configure the output html.
\end{itemize}

The output HTML arranges the variables into sections and allows the user to add comments and 
other information to the summary by adding comments to the PROCESS IN.DAT. The comments in the 
IN.DAT take the following form:

\begin{mdframed}
 \begin{verbatim}
  
  #header-physics : Comment under header called physics

  #constraint-1 : Comment for constraint number 1
  icc = 1

  #iteration-variable-10 : Comment for iteration variable 10
  ixc        = 10 * hfact

  #in-neped : Comment for input neped
  neped = 0.678e20 * Electron density of pedestal (/m3) (ipedestal=1)

 \end{verbatim}
\end{mdframed}

The \texttt{IN.DAT} is appended to the end of the \texttt{MFILE.DAT} and the Python gets this 
information from there. The comments have to follow the format above. It is not ideally run on 
every PROCESS run, but is useful for summarising important PROCESS results. The options for 
the \texttt{output\_summary.py} are:\\

\begin{mdframed}
 \begin{verbatim}
  output_summary.py [-h] [-f MFILENAME] [-o OUTFILENAME]

  Create PROCESS output document.For info contact james.morris2@ukaea.uk

  optional arguments:
   -h, --help      show this help message and exit
   -f MFILENAME    specify PROCESS MFILE
   -o OUTFILENAME  specify output file
 \end{verbatim}
\end{mdframed}

The options for the \texttt{output\_detailed.py} are:\\

\begin{mdframed}
 \begin{verbatim}
  output_detailed.py [-h] [-f MFILENAME] [-j JSONFILE] [-o OUTFILENAME]

  Create PROCESS output document.For info contact james.morris2@ukaea.uk

  optional arguments:
   -h, --help      show this help message and exit
   -f MFILENAME    specify PROCESS MFILE
   -j JSONFILE     specify JSON file location and name
   -o OUTFILENAME  specify output file
 \end{verbatim}
\end{mdframed}

\texttt{Output\_detailed.py} also requires a configuration file named 
\texttt{output\_detailed.json}. This JSON file contains the grouping of the output 
and allows the user to adjust what is output and where.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Output Plotting}


%-------------------------------
\subsubsection{Output plotting: create data file (make\_plot\_dat.py)}

Creates a \plotdat-type file from \mfile.  This is required by \texttt{plot\_sweep.py}.

\begin{description}
\item{\textbf{Input:}}
\verb|make_plot_dat.conf|, \mfile\

\item{\textbf{Output:}}
\verb|make_plot_dat.out|
\end{description}

\paragraph{Configuration Options:}

Optional arguments are:
\begin{quote}
\begin{verbatim}
# new variables for output
make_plot_dat.py -p rmajor
# writes make_plot_dat.out in columns
make_plot_dat.py --columns
# resets make_plot_dat.conf to PLOT.DAT layout
make_plot_dat.py --reset-config
# file to read as input
make_plot_dat.py -f MFILE.DAT
# run with default parameters
make_plot_dat.py --defaults
\end{verbatim}
\end{quote}

An example version of \texttt{make\_plot\_dat.conf} might look like this:
\begin{framed}
\begin{verbatim}
# make_plot_dat.out config file.
rmajor
aspect
rminor
bt
powfmw
pnetelmw
te
pdivt
strtf1
strtf2
\end{verbatim}
\end{framed}


%-------------------------------
\subsubsection{Create a two-page summary (plot\_proc.py)}

A utility to produce a two-page summary of the output, including the major
parameters, poloidal and toroidal cross-sections, and temperature and density profiles.

\begin{description}
\item{\textbf{Input:}}
 \mfile

\item{\textbf{Output:}}
\verb|SUMMARY.pdf| (or as specified by user)
\end{description}

\paragraph{Configuration Options:}

Optional arguments are:
\begin{quote}
\begin{verbatim}
usage: plot_proc.py [-h] [-f FILENAME] [-s]

Produces a two page summary of the PROCESS MFILE output, using the MFILE. For
info contact michael.kovari@ukaea.uk or james.morris2@ukaea.uk

optional arguments:
  -h, --help   show this help message and exit
  -f FILENAME  specify input/output file prefix
  -s, --show   show plot as well as saving figure
\end{verbatim}
\end{quote}

The individual parameters displayed in the 2 page summary are defined as follows:

\begin{description}
\item[\texttt{runtitle}] Variable describing the purpose of the run
\item[\texttt{PROCESS version}]Tagged version of \process\/ used for the run.
\item[\texttt{Date}] Date of the \process\/ run
\item[\texttt{Time}] Time of the \process\/ run
\item[\texttt{User}] Nave of the user who ran \process.
\item[\texttt{Optimisation}] Figure of merit (\texttt{minmax}, see vardes.html) for constrained optimisation (see Userguide).
\item[\texttt{Plasma Composition}] Number densities of several ion species relative to the electron density.
\item[\texttt{Coil Currents etc.}] Peak coil currents of the PF coils in $MA$, flux swing of the central solenoid used for startup and total available in $Wb$. Total burn time \texttt{tburn} in hrs (see Userguide).
\item[\texttt{TF coils}] Describes the type, the peak field at the TF coil including ripple at the outboard edge of the inboard TF coil winding pack in $T$, the ratio of operating to superconducting critical current in TF coil $I/I_{crit}$, the temperature margin with respect to critical temperature of super conductor in $K$, Van Mises stresses on TF coils
\item[\texttt{Cost of electricity}] This is the cost of electricity in $/MWh$. Check the respective cost model for the reference year of the inflation used.
\item[\texttt{Geometry}] This is the major radius $R_0$, the minor radius $a$, the aspect ratio $A$, the plasma elongation at the 95\% flux surface $\kappa_{95}$, the plasma triangularity at the 95\% flux surface $\delta_{95}$, the surface area of the plasma, the plasma volume, the number of TF coils, the inboard and outboard thicknesses of the blanket and shield as well as the total fusion power.
\item[\texttt{Power flows}] Average neutron wall load $W_{all}=\frac{P_{neutrons}}{S_{plasma,surface}f_{user}}$ \cite{kovari_eng}, the normalised radius of the `core' region $\rho_{core}$ used in the radiation correction of the confinement scaling \cite{hanni_radiation,Lux2016}, the electron density at the pedestal top $n_{e,ped}[m^{-3}]$, the normalised radius $\rho=r/a$ at the pedestal top, the helium fraction relative to the electron density, the core radiation $P_{rad} (\rho<\rho_{core})$ subtracted from $P_{heat}$ in confinement scaling and $W_{th}$, the total radidation inside the separatrix, the nuclear heating power to blanket $P_{nuc,blkt}= P_{neutr} (1-e^{-\frac{\Delta x_{blkt}}{\lambda_{decay}}})$, the nuclear heating power to the shield $P_{nuc,shld}=P_{neutr}-P_{nuc,blkt}$, the power crossing the separatrix into the SoL/Divertor $P_{sep}$, the L-H threshold power $P_{LH}$, the divertor lifetime in years, the high grade heat for electricity production $P_{therm}$, gross cycle efficiency $P_{e,gross}/P_{therm}$, Net cycle efficiency $\frac{P_{e,gross}-P_{heat,pump}}{P_{therm}-P_{heat,pump}}$, Net electric power $P_{e,net}=P_{e,gross}-P_{recirc}$, Plant efficiency $P_{e,net}/P_{fus}$.
\item[Physics] Plasma current $I_P[MA]$, vaccuum magnetic field at in the plasma centre $B_T(R_0)$, the safety factor at the 95\% flux surface $q_{95}$, definitions of $\beta$ as given in \cite{kovari_physics}, the volume averaged electron temperature $\langle T_e\rangle$ and density $\langle n_e\rangle$, the fraction of the line averaged electron density over the Greenwald density $\langle n_{e,line}\rangle / n_{GW}$, the peaking of the electron temperature $T_{e,0}/\langle T_e\rangle$ and density  $n_{e,0}/\langle n_{e,vol}\rangle$, core and SoL effective charge $Z_{eff}=\sum_i f_iZ_i^2$, impurity fraction $f_Z=n_Z/\langle n_e\rangle$, H-factor and confinement time are calculated using a radiation corrected confinement scaling \cite{hanni_radiation, Lux2016}.
\item[Neutral Beam Current Drive] the steady state auxiliary power used for heating and current drive during the flat top phase (NOT to be confused with the start up or ramp down power requirements), part of the auxiliary power that is used for heating only, but not current drive, current drive fractions for the inductive, auxiliary and bootstrap current, the neutral beam current drive efficiency $\gamma_{NB}$, the neutral beam energy, the plasma heating used in the calculation of the confinement scaling/H-factor $P_{aux} + P_\alpha - P_{rad,core}$, the divertor figure of merit $P_{sep}/R$, $P_{sep}/(\langle n_e\rangle R)$,
the fraction of the power crossing the separatrix with respect to the LH-threshold power $P_{sep}/P_{LH}$, the non-radiation corrected H-factor (calculated for info only).
\end{description}


%-----------------------------------
\subsubsection{Plot scan results (plot\_mfile\_sweep.py)}

This utility plots normalised values of the iteration variables output by a parameter scan. Zero indicates an iteration variable at its lower bound and 1 an iteration variable at its upper bound.

\begin{description}
\item{\textbf{Input:}}
 \mfile

\item{\textbf{Output:}}
\texttt{sweep\_fig.pdf} (default or as specified by user)
\end{description}

Optional arguments are:
\begin{quote}
\begin{verbatim}
# creates sweep_fig.pdf with R0, te, aspect (same variable names as in MFILE.DAT)
python plot_mfile_sweep.py -p rmajor te aspect
# creates demo1.png with Te, n
python plot_mfile_sweep.py -o demo1.png -p te dene
# creates a sweep_fig.pdf with R0, aspect with a different MFILE.DAT
python plot_mfile_sweep.py -f diff_mfile.dat -p rmajor aspect
# Show plot to screen instead of saving with R0 and aspect
python plot_mfile_sweep.py -p rmajor aspect --show

Use -h or --help for help

\end{verbatim}
\end{quote}

%-----------------------------------
\subsubsection{Plot iteration variables and constraint residuals (diagnose\_process.py)}

This utility aids the user to interpret \process\/ runs that do not find a feasible solution (unless \process\/ has terminated prematurely). It reads the \mfile\ and plots
the normalised iteration variables, i.e.\ the iteration variable values
normalised to their bounds such that 0 indicates an iteration variable at its
lower bound and 1 an iteration variable at its upper bound. Furthermore, it
shows the normalised constraint residuals.

\begin{description}
\item{\textbf{Input:}}
 \mfile

\item{\textbf{Output:}}
  Displays plots on screen, still need to be saved by the user! (Remember to
  use -Y or -X, if \texttt{ssh}ing into a remote machine!)

\end{description}

Optional arguments are:
\begin{quote}
\begin{verbatim}
# allows to specify another location/name for the MFILE
python diagnose_process.py -f MFILE.DAT

Use -h or --help for help

\end{verbatim}
\end{quote}


%------------------------------------
\subsubsection{Plot two parameters from many MFILES (plot\_comparison.py)}

\begin{quote}
\begin{verbatim}
usage: plot_comparison.py [-h] [-x XAXIS] [-y YAXIS] [-e END] [f [f ...]]

Program to display the evolution of two variables in a selection of MFILEs.

positional arguments:
  f                     list of MFiles to be plotted; default = MFILE.DAT

optional arguments:
  -h, --help            show this help message and exit
  -x XAXIS, --xaxis XAXIS
                        x-axis, default=rmajor
  -y YAXIS, --yaxis YAXIS
                        y-axis, default=powfmw
  -e END, --end END     file format default = pdf
\end{verbatim}
\end{quote}

\subsubsection{Plot pie chart of cost breakdown (cost\_pie.py)}

This utility plots the cost breakdown as a pie chart.  For both cost models it produces a pie chart of the costs grouped by item, so that the most expensive areas can easily be identified.  For the 1990 cost model, an additional plot showing how the direct, indirect and contingency costs contribute to the overall budget is shown. 

\begin{description}
	\item{\textbf{Input:}}
	\mfile
	
	\item{\textbf{Output:}}
	Displays plot of the cost breakdown to screen.  For the 1990 cost model, the breakdown for direct, indirect and contingency is also shown.  These can be saved with -s argument (cost\_pie.png and direct\_cost\_pie.png).
	
\end{description}

Optional arguments are:
\begin{quote}
\begin{verbatim}
usage: cost_pie.py [-h] [-f MFILE] [-s]

Displays the cost breakdown as a pie chart.
For more information contact Stuart.Muldrew@ukaea.uk

optional arguments:
-h, --help  show this help message and exit
-f MFILE    specify the MFILE (default=MFILE.DAT)
-s, --save  save as well as showing figure

\end{verbatim}
\end{quote}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Uncertainty Tools}

In this section, we explain the usage of the \process\/ tools to both evaluate
the uncertainties of a design point as well as display them using a simple
plotting facility.

Note that the uncertainty evaluation tool has a significantly longer run time
than typical evaluations of \process\/ design points and therefore should only
be used once a suitable design point has been found.  As only user selected
output data is kept, the user is recommended to put careful thought into the
list of needed output variables.

\subsubsection{evaluate\_uncertainties.py}
\label{subsec:evalunc}
This program evaluates the uncertainties of a single \process\ design point by
use of a Monte Carlo method as described in \cite{WPPMI2014Report}. It takes a
set of uncertain parameters as input, each of which can have either a Gaussian or a flat ('top-hat') probability distribution. These are specified together with optional details about the
\process\ run in a configuration file. Additionally, an \indat\ file
describing the relevant design point needs to be present. (If necessary this can be created
from an \mfile\ by using the \texttt{write\_new\_indat.py} tool.)

When running the \texttt{evaluate\_uncertainties.py} tool, optional arguments are:
\begin{quote}
\begin{verbatim}
#to specify another location/name for the configfile
evaluate_uncertainties.py -f CONFIGFILE

Use -h or --help for help
\end{verbatim}
\end{quote}



\begin{description}
\item{\textbf{Input:}} \texttt{evaluate\_uncertainties.json},\\
\indat\ (or an alternative input file as specified in the config file)

\item{\textbf{Output:}} \\
\texttt{uncertainties.nc}. This file (NetCDF format) can be visualised using the \texttt{display\_uncertainties.py} tool. \\
\texttt{Readme.txt},\\
\texttt{process.log}, \\
\texttt{UQ\_error\_summary.txt},\\
\process\ output from the last run.

\end{description}
The configuration file \texttt{evaluate\_uncertainties.json} uses the JSON
format\footnote{www.json.org}, and has the following style
\begin{framed}
\begin{verbatim}
{
	"_description": "Config file for uncertainties evaluation",
	"_author": "Hanni Lux",

	"config": {
		  "runtitle": "testrun for uncertainty tool on DEMO2",
		  "IN.DAT_path": "IN.DAT_demo2",
		  "process_bin": "~PROCESS/master/process.exe",
		  "working_directory": "Run1",
		  "pseudorandom_seed": 2
		  },
	"uncertainties": [
          	     {
               	     "Varname":"flhthresh",
               	     "Errortype":"Gaussian",
               	     "Mean":1.0,
               	     "Std":0.05
          	     },
          	     {
               	     "Varname":"coreradius",
               	     "Errortype":"Uniform",
               	     "Lowerbound":0.6,
               	     "Upperbound":0.9
          	     },
          	     {
               	     "Varname":"etanbi",
               	     "Errortype":"Relative",
               	     "Mean":0.3,
               	     "Percentage":10.0
          	     },
          	     {
               	     "Varname":"boundu(9)",
               	     "Errortype":"LowerHalfGaussian",
               	     "Mean":1.2,
               	     "Std":0.1
          	     },
          	     {
               	     "Varname":"boundl(103)",
               	     "Errortype":"UpperHalfGaussian",
               	     "Mean":1.0,
               	     "Std":0.25
          	     }
	     	],
     "output_vars": [ "rmajor", "dene", "te", "bt"],
     "no_samples": 1000
}
\end{verbatim}
\end{framed}
By convention, we have designated metadata about the \process\ runs as having
a preceding underscore to distinguish these values from the other
configuration data used directly by the tools or \process\
itself. Furthermore, all the optional attributes that can be changed when
running \process\ from most Python utilities like
e.g. \texttt{run\_process.py} can be specified in the ``config'' section. All
these values have default values and do not need to be set.
\begin{description}
\item[\texttt{runtitle}] is a one line description of the purpose of the run
  to be saved in Readme.txt in the working directory as well as the runtitle
  parameter in the \outdat\ and \mfile\ files. Per default it is empty.
\item[\texttt{IN.DAT\_path}] is the name/path of the \indat\ file describing
  the design point. If not specified it is assumed to be \indat.
\item[\texttt{process\_bin}] is the process binary that should be used. The
  default assumes that the user works on the CCFE Fusion Linux machines and
  has executed the module commands for \process\ as described in the Userguide. Then either the master or development branch of
  process is being used depending on which module has been loaded.
\item[\texttt{working\_directory}] represents the working directory, in which
  \process\ will be executed, in case this is supposed to be different to the
  current directory which can be helpful when executing several runs with
  slightly different setups.
\item[\texttt{pseudorandom\_seed}] is the value of the seed for the random
  number generator. It can be any integer value. If it is not specified, its
  default value is taken from the system clock.
\end{description}

Other parameters that can be specified in the config section are
\texttt{Niter} and \texttt{factor}. Both do not typically need to be changed
by the user. \texttt{Niter} is the maximum number of retries that the tool
will attempt, if \process\ fails to find a feasible solution. This means that
the tool varies the start values of the iteration variables within a factor
given by \texttt{factor} of the original values as this does not change the
physical meaning of the input file, but can help the solver to find a better
starting point for its iteration. Their default values are \texttt{Niter}=10
and \texttt{factor}=1.5.

Any uncertain parameters should be specified in the ``uncertainties''
section. Each parameter is specified in its own sub dictionary as shown in the
example. For each, the \texttt{Varname} and \texttt{Errortype} need to be
specified as well as the \texttt{Mean} and standard deviation \texttt{Std} for
Gaussian type errors as well as \texttt{Lowerbound} and \texttt{Upperbound}
for Uniform or \texttt{Mean} and a \texttt{Percentage} for Relative errors. Apart from a standard Gaussian distribution, also a lower and an upper half Gaussian distribution are available that have a sharp cut off at the mean. Please note, that \emph{all distributions are being cut off at the boundaries for the input values for \process!}  At
least one uncertain parameter has to be specified for the program to run and
technically there is no upper limit as to how many uncertain parameters can be
used. However, for large numbers of uncertain parameters it is recommended to
increase the number of sampling points.

There are a number of other parameters in the configuration file that can be specified:
\begin{description}
\item[\texttt{output\_vars}] is a list of strings of output variable names in
  the \mfile. These are the variables saved. This list is empty by default and
  it is therefore crucial for the user to specify the variables of interest
  because otherwise the tool will not run.
\item[\texttt{no\_samples}] sets the number of sample points in the Monte
  Carlo method. It is by default set to its recommended minimum value of 1000,
  but the user should contemplate higher values especially if a large number
  of uncertain parameters is involved.
\end{description}
Two parameters that can be further set in the config file (but are not
recommended to be changed) are the number of scan points \texttt{no\_scans}
which is by default 5 and the number of allowed unfeasible points in a scan
\texttt{no\_allowed\_unfeasible} which is 2 as recommended in
\cite{WPPMI2014Report}.

As the distributions of the uncertainties do not have to be represented by a
simple Gaussian, reducing the output to two simple numbers like a mean and a
standard deviation is not typically possible. Therefore, we have decided to
keep all sampled points in the output files. However, to reduce the amount of
data we have decided to only store the user specified parameters in the form
of a NetCDF binary file. Given that a scan is performed at each sample point,
only the last of these scan points is ever kept for evaluation. (There is an
option for developers to keep all the data for debugging purposes. However,
this should typically not be used in production runs.) These files can be
visualised using the \texttt{display\_uncertainties.py} tool.

The UQ\_error\_summary.txt file is an ascii text file summarising all values of the uncertain parameter inputs, the normalised values of iteration variables (labelled ``n\_''variable name) and whether their runs have found a feasible solution (ifail=1), have encountered any PROCESS errors (ifail=-1, error\_status=3) or whether they have not found a feasible solution (all other ifail values, for details see PROCESS user guide). This file can be used to analyse parameter spaces prone to errors.



\subsubsection{display\_uncertainties.py}

This is a utility to display the output file \texttt{uncertainties.nc} created by the \texttt{evaluate\_uncertainties.py} tool described above.

By default, if run in the working directory of an uncertainty evaluation, it creates a scatter plot of each user defined output parameter against the next parameter in the list.  It also shows the 1D histograms of each parameter distribution. If two specific variables are given as arguments, the tool plots only these two against each other.

\begin{description}
\item{\textbf{Input:}}
 \texttt{uncertainties.nc}

\item{\textbf{Output:}}
Uncertainties\_varname1\_varname2.pdf
\end{description}

Usage:
\begin{verbatim}
display_uncertainties.py [-h] [-f FILENAME] [-e END] [v [v ...]]

Program to display uncertainties of a given PROCESS design point.

positional arguments:
  v              list of variables to be plotted; default = all

optional arguments:
  -h, --help     show this help message and exit
  -f FILENAME, --filename FILENAME
                 uncertainties data file, default = uncertainties.nc
  -e END, --end END     file format default = .pdf
\end{verbatim}


\subsubsection{diagnose\_uncertainties.py}
This is a Python facility to display the input parameter distributions in the final runs vs. the ones specified in the input file. This can be used to determine whether the input distributions are sufficiently sampled or whether the resulting distributions are skewed due to unfeasible designs being excluded.

\begin{description}
\item{\textbf{Input:}}
 \texttt{uncertainties.nc}, \texttt{evaluate\_uncertainties.json}

\item{\textbf{Output:}}
Uncertainties\_Diagnostic\_varname.pdf
\end{description}

Usage:
\begin{verbatim}
diagnose_uncertainties.py [-h] [-e END] [-u UNCERTAINTIES] [-f FILENAME]

Program to check the final uncertainty distributions in the input parameters.

optional arguments:
  -h, --help            show this help message and exit
  -e END, --end END     file format default =pdf
  -u UNCERTAINTIES, --uncertainties UNCERTAINTIES
                        uncertainties config file default =
                        evaluate_uncertainties.json
  -f FILENAME, --filename FILENAME
                        uncertainties data file, default =uncertainties.nc

\end{verbatim}

\subsection{Batch Jobs}
As \process\/ typically runs very fast and does not produce much data output, it is not typically necessary to submit \process\/ runs or any of the python executables as a batch job to the fusion linux machines. However, the \texttt{evaluate\_uncertainties.py} tool is one example of a python tool for \process\/ that does run for a long time and does create a lots of output. As the CPU time limit for any non-batch jobs on the fuslw machines is 30 Minutes, any decently sampled \texttt{evaluate\_uncertainties.py} run will need to be submitted as a batch job. (Please note, that if you have forgotten to submit your job as a batch job, your job will be terminated after 30 CPU minutes, but as the output is written to file continuously, you should not loose any of the output that has been produced until then.)

To submit a batch job, first create a file called e.g. myjob.cmd. It should contain the following content
\begin{verbatim}
# @ executable = evaluate_uncertainties.py
# @ arguments
# @ input = /dev/null
# @ output = /ABSOLUTE_PATH_TO_WORK_DIR/ll.out
# @ error = /ABSOLUTE_PATH_TO_WORK_DIR/ll.err
# @ initialdir = /ABSOLUTE_PATH_TO_WORK_DIR/
# @ notify_user = USERNAME
# @ notification = complete
# @ queue
module use /home/PROCESS/modules
module swap python
module load process/master
\end{verbatim}
Once you have created the file you can submit a batch job by typing
\begin{verbatim}
llsubmit myjob.cmd
\end{verbatim}

While your job is running you can keep track of its progress by typing \texttt{llq} or \texttt{xloadl}. More information and help with troubleshooting can be found under \url{http://fusweb1.fusion.ccfe.ac.uk/computing/funfaq/ll/}.

As the uncertainties.nc output file can get quite large, it might be indicated to write the output to the /scratch or /tmp directories as they have faster I/O. Please remember to copy your results into your home directory afterwards, as these directories are not backed up and will be frequently cleaned.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{test\_suite.py}
\label{sec:testsuite}

The PROCESS test suite allows PROCESS developers to quickly test new modifications to PROCESS using a defined library of reference cases. The test suite is bundled with PROCESS and is a single Python script (\textbf{test\_suite.py}) with a number of options.

The test suite will provide the following output

\begin{itemize}
\item Summary to terminal and file (\textbf{summary.log})
\item PROCESS terminal output log to file for each test case (\textbf{run.log})
\item PROCESS error log to terminal and to file if errors for each test case (\textbf{error.log})
\item New MFILE.DATs and OUT.DATs for each test case (\textbf{new.MFILE.DAT} and \textbf{new.OUT.DAT})
\end{itemize}

\subsubsection{Folder Structure}

The PROCESS folder structure is shown below. The test suite folder (\textbf{test\_suite}) is in the main directory with the FORTRAN files. Inside the test suite folder there is the main code (\textbf{test\_suite.py}) as well as the folders containing the reference cases (\textbf{test\_files}). The figure below shows the folder structure for the test\_suite.

\tikzstyle{every node}=[draw=black,thick,anchor=west]
\tikzstyle{selected}=[draw=red,fill=red!30]
\tikzstyle{optional}=[dashed,fill=gray!50]

\begin{figure}[!hb]
\centering
\begin{tikzpicture}[%
  grow via three points={one child at (0.5,-0.7) and
  two children at (0.5,-0.7) and (0.5,-1.4)},
  edge from parent path={(\tikzparentnode.south) |- (\tikzchildnode.west)}]
  \node {process}
    child { node [selected] {test\_suite}
      child { node {test\_suite.py}}
      child { node {test\_files}
        child { node {Example Test case}
          child { node {README.txt}}
          child { node {IN.DAT}}
          child { node {ref.IN.DAT}}
          child { node {ref.MFILE.DAT}}
          child { node {ref.OUT.DAT}}
          }
        }
      child {}
      child {}
      child {}
      child {}
      child {}
      child {}
      child { node {test\_area}
        child { node {summary.log}}
        child { node {Example Test case}
          child { node {README.txt}}
          child { node {run.log}}
          child { node {diff.log}}
          child { node {IN.DAT}}
          child { node {ref.IN.DAT}}
          child { node {ref.MFILE.DAT}}
          child { node {ref.OUT.DAT}}
          child { node {new.MFILE.DAT}}
          child { node {new.OUT.DAT}}
          }
        }
     };
\end{tikzpicture}
\caption{PROCESS Test suite folder structure after a test run. The test\_area folder is where the output of the test run is stored. Each test case has a README file which outlines the reasoning for
the test.}
\label{fig:test suite struct}
\end{figure}

\subsubsection{Adding a reference case}
To add a reference case if you have a local PROCESS repository:

\begin{enumerate}
  \item Have an IN.DAT that works with the current version of PROCESS
  \item Run PROCESS to create an OUT.DAT and MFILE.DAT
  \item Create a folder in the location \textbf{/my\_develop/test\_suite/test\_files/[test\_name]} with a suitable name for the test case (if your local PROCESS folder is \texttt{my\_develop}).
  \item Copy your IN.DAT, OUT.DAT and MFILE.DAT into this folder
  \item Copy IN.DAT as \textbf{ref.IN.DAT}
  \item Rename OUT.DAT as \textbf{ref.OUT.DAT}
  \item Rename MFILE.DAT as \textbf{ref.MFILE.DAT}
  \item \texttt{cd ../..}  to return to test\_suite folder
  \item \texttt{test\_suite.py}  to run the test suite to check it works
  \item Commit to Git locally and push to the central repository (see instructions in PROCESS manual)
\end{enumerate}

\subsubsection{Running the Test Suite}

To run the test suite the user should go to the folder \textbf{/process/test\_suite/} and then run the Python file \textbf{test\_suite.py}. The test suite Python script has the following optional arguments.\\
\begin{verbatim}
 python test_suite.py [options]

 -h - -help         show usage

 -s --save          save test output to folder with PROCESS revision
					number in it(e.g. test_r383)

 -d --diff [val]    set allowed difference between reference case and
					new output in percentage terms.

 -r --ref           choose reference folder to use for the test cases
                    default is "test_files"

 --debug            run reference cases prefixed with "error_" for
                    testing of the error handling in the test suite

 Examples

    python test_suite.py -d 10 --save

    python test_suite.py -d 1

\end{verbatim}


\subsubsection{Test Suite Output Formatting}

\subsubsection*{summary.log}

The summary.log file mirrors what was displayed to the terminal during a test suite run. It will look something like the following.

\begin{verbatim}

PROCESS Test Suite

Date: 2015-12-03
Diff set to: 5.0%

PROCESS Test Cases

Test ==>  DEMO1_a31_06_2015             DIFF(6)
Test ==>  costs_paper                   OK
Test ==>  test 3                        ERROR
Test ==>  test 4                        OK

PROCESS version r[version] test run complete

\end{verbatim}

\subsubsection*{diff.log}

This file will contain the differences between the reference case and the new run for a given test. The file will look like the example below.

\begin{verbatim}

PROCESS Test Suite

Test Case: [test_name]
Difference value: [diff]

Differences above allowed value:

    var | ref | new | %
    a     10    15    50
    b     10    9     10
    ...   ...   ...   ...

Variables in ref NOT IN new:

    var 1
    var 2
    ...

Variables in new NOT IN ref:

    var 1
    var 2
    ...

\end{verbatim}

\subsubsection*{run.log}

Run.log will take the output to the terminal for each PROCESS test case and dump it to a 
file in the test folder in \textbf{/process/test\_suite/test\_area/[test\_name]/}. If 
there is an error while running PROCESS this will be highlighted in \textbf{summary.log} 
and then the user can inspect the output in run.log\\

\subsubsection*{new.MFILE.DAT}

This is the MFILE.DAT the test suite created when running a given test case. After running 
the test suite will move this file to the folder 
\textbf{/process/test\_suite/test\_area/[test\_name]/}.\\

\subsubsection*{new.OUT.DAT}

This is the OUT.DAT the test suite created when running a given test case. After running 
the test suite will move this file to the folder 
\textbf{/process/test\_suite/test\_area/[test\_name]/}.\\


\subsection{Miscellaneous}

%-----------------------------------
\subsubsection{fit\_profile.py}

This is a Python tool to fit a general temperature or density profile as given
by the pedestalised profile parametrisation (\texttt{ipedestal} =1) to an
ascii table. It is using a least squares method and is fitting the position of
the pedestal as well as the peaking factors.  Optional arguments are
\begin{verbatim}

  -h, --help            show this help message and exit
  -f FILENAME, --filename FILENAME
                        ascii file containing data in columns, default =
                        profile.txt
  -r RHO, --rho RHO     column of the normalised radius rho=r/a, default = 0
  -n DENSITY, --density DENSITY
                        column of the density profile, default = 1
  -t TEMPERATURE, --temperature TEMPERATURE
                        column of the temperature profile, default = 2
  -rn RHOPEDN, --rhopedn RHOPEDN
                        user defined initial guess of the density pedestal
                        position, if outside [0,1] starts at 0.9, default =
                        0.9
  -rt RHOPEDT, --rhopedt RHOPEDT
                        user defined initial guess of the temperature pedestal
                        position, if outside [0,1], starts at 0.9, default =
                        0.9

\end{verbatim}
If the column of the density or temperature data does not exist, it is
ignored. A warning is issued.

%-----------------------------------
\subsubsection{create\_dicts.py}

This automatically generates the \texttt{process\_dicts.py} file used by \process\/ utility programs.  It does this by scanning the Fortran source code.  The standard output should be redirected, using\\
\begin{verbatim}
create_dicts.py > process_dicts.py
\end{verbatim}



\section{Python Libraries}
\label{sec:py_lib}

All library modules and functions are documented using docstrings. These can
be accessed by reading the code directly or via the \texttt{help()} function
in Python.

\subsection{in\_dat.py}

A set of Python classes to read, modify and write an \indat\ file.

\begin{description}

\item{\verb|INVariable(name, value, comment="")| } Initialises an \indat\
  variable class which requires a name and a value.

\end{description}

\rule{\textwidth}{0.4pt}

\begin{description}

\item{\verb|INModule(name)|} Initialises an \indat\ module class which
  requires a name. This class stores information for an \indat\ file which has
  modules separated with lines with \$MODULE\_NAME and \$END.

\item{\verb|INModule.add_variable(var)|} Adds an \verb|INVariable| object to
  the \verb|INModule| class.

\item{\verb|INModule.remove_variable(variable_name)|} Removes an
  \verb|INVariable| object from the \verb|INModule| class.

\item{\verb|INModule.add_line(line)|} Adds a line from the \indat\ that isn't
  a variable line (e.g. a comment) to the \verb|INModule| class.

\item{\verb|INModule.get_var(var_name)|} Returns an \verb|INVariable| object
  from the \verb|INModule| class.

\item{\verb|INModule.add_constraint_eqn(eqn_number)|} Adds constraint
  equation \verb|eqn_number| to the list of constraint equations
  \verb|InVariable| class if the equation is not already in the list.

\item{\verb|INModule.remove_constraint_eqn(eqn_number)|} Removes
  constraint equation \verb|eqn_number| from the list of constraint
  equations \verb|InVariable| class if the equation is already in the list.

\item{\verb|INModule.add_iteration_variable(var_number)|} Adds iteration
  variable \verb|var_number| to the list of iteration variables
  \verb|InVariable| class if the variable is not already in the list.

\item{\verb|INModule.remove_iteration_variable(var_number)|} Removes
  iteration variable \verb|var_number| to the list of iteration variables
  \verb|InVariable| class if the variable is already in the list.

\end{description}

\rule{\textwidth}{0.4pt}

\begin{description}

\item{\verb|INDATClassic(filename="IN.DAT")| } Initialises an \indat\ class
  which can be given a different filename. This class is used for an \indat\
  with a module structure.

\item{\verb|INDATClassic.read_in_dat()| } Reads an \indat\ file with modular
  structure.

\item{\verb|INDATClassic.write_in_dat(filename="new_IN.DAT")| } Writes a new
  \indat\ with modular structure.

\item{\verb|INDATNew.read_in_dat()| } Reads an \indat\ file without modular
  structure.

\item{\verb|INDATNew.write_in_dat(filename="new_IN.DAT")| } Writes a new
  \indat\ without modular structure.

\item{\verb|INDATNew.add_variable(var)| } Adds an \verb|INVariable| object to
  the \verb|INDATNew| class.

\item{\verb|INDATNew.remove_variable(var_name)| } Removes an
  \verb|INVariable| object from the \verb|INDATNew| class.

\item{\verb|INDATNew.add_constraint_eqn(eqn_number)|} Adds constraint
  equation \verb|eqn_number| to the list of constraint equations
  \verb|InVariable| class if the equation is not already in the list.

\item{\verb|INDATNew.remove_constraint_eqn(eqn_number)|} Removes
  constraint equation \verb|eqn_number| from the list of constraint
  equations \verb|InVariable| class if the equation is already in the list.

\item{\verb|INDATNew.add_iteration_variable(var_number)| } Adds iteration
  variable \verb|var_number| to the list of iteration variables
  \verb|InVariable| class if the variable is not already in the list.

\item{\verb|INDATNew.remove_iteration_variable(var_number)| } Removes
  iteration variable \verb|var_number| to the list of iteration variables
  \verb|InVariable| class if the variable is already in the list.

\end{description}

\rule{\textwidth}{0.4pt}

\begin{description}

\item{\verb|clear_lines(lines)|} Removes comment only lines and replaces
  multiple empty lines with a single empty line.

\item{\verb|variable_type(var_name, var_value)|} Checks the type of an \indat\
  variable using \verb|DICT_VAR_TYPE|

\item{\verb|fortran_python_scientific(var_value)|} Changes from FORTRAN double
  precision notation \verb|D| to Python's \verb|e| notation.

\end{description}

\subsection{mfile.py}

A set of Python classes to read and extract data from \mfile.

\begin{description}

\item{\verb|MFileVariable(var_name, var_description)|} Object to contain
  information for a single \mfile\ variable.

\item{\verb|MFileVariable.set_scan(scan_number, scan_value)|} Sets the
  variable value for scan number \verb|scan_number|

\item{\verb|MFileVariable.get_scan(scan_number)|} Returns the variable value
  for scan number \verb|scan_number|

\item{\verb|MFileVariable.get_scans()|} Returns the variable value for all
  scans.

\end{description}

\rule{\textwidth}{0.4pt}

\begin{description}

\item{\verb|MFile(filename="MFILE.DAT")|} Object to contain information for
  all variables in an \mfile\ for all scans.

\item{\verb|MFile.search_keys(variable)|} Search for an MFILE variable in the
  data dictionary.

\item{\verb|MFile.search_des(description)|} Search for an MFILE description in
  the data dictionary.

\item{\verb|MFile.make_plot_dat(custom_keys, filename="make_plot_dat.out", file_format="row")|}
  Create a \plotdat\ equivalent for the variables in \verb|custom_keys| in
  either row or column format.

\item{\verb|MFile.get_num_scans()|} Returns the number of scans in the
  \mfile

\end{description}

\rule{\textwidth}{0.4pt}

\begin{description}

\item{\verb|read_mplot_conf(filename="make_plot_dat.conf")|} Reads the config
  file \verb|make_plot_dat.conf| and fills the list \verb|custom_keys| with
  these variables.

\item{\verb|write_mplot_conf(filename="make_plot_dat.conf")|} Writes a new
  \verb|make_plot_dat.conf| adding any additional variables that the user
  \verb|gave make_plot_dat.py| at runtime.

\end{description}

\subsection{process\_funcs.py}

This library contains a collection of functions used by various \process\
utilities.

\begin{description}

\item{\verb|get_neqns_itervars(wdir='.')| } Returns the number of equations
  and a list of variable names of all iteration variables.

\item{\verb|update_ixc_bounds(wdir='.')|} Updates the lower and upper bounds
  in \verb|DICT_IXC_BOUNDS| from \indat.

\item{\verb|get_variable_range(itervars, factor, wdir='.')|} Returns the lower
  and upper bounds of the variable range for each iteration variable.

  \texttt{itervars}: string list of all iteration variable names

  \texttt{factor}: defines the variation range for non-f-values by setting
  them to value * factor and value / factor respectively while taking their
  \process\ bounds into account.

  For f-values the allowed range is equal to their \process\ bounds.

\item{\verb|check_logfile(logfile='process.log')|} Checks the log file of the
  \process\ output.  Stops if an error occurred that needs to be fixed before
  rerunning.

\item{\verb|process_stopped(logfile='process.log')|} Checks the \process\
  logfile whether it has prematurely stopped.

\item{\verb|process_warnings(logfile='process.log')|} Checks the \process\
  logfile whether any warnings have occurred.

\item{\verb|mfile_exists()|} Checks whether \mfile\ exists.

\item{\verb|no_unfeasible_mfile(wdir='.')|} Returns the number of unfeasible
  points in a scan in \mfile.

\item{\verb|no_unfeasible_outdat(wdir='.')|} Returns the number of unfeasible
  points in a scan in \outdat.

\item{\verb|vary_iteration_variables(itervars, lbs, ubs) |} Changes the
  iteration variables in \indat\ within given bounds.

  \texttt{itervars}: string list of all iteration variable names

  \texttt{lbs}: float list of lower bounds for variables

  \texttt{ubs}: float list of upper bounds for variables

\item{\verb|get_solution_from_mfile(neqns, nvars, wdir='.')|} Returns:-

\begin{itemize}
\item \texttt{ifail}: error value of \process
\item the objective functions
\item the square root of the sum of the squares of the constraints
\item a list of the final iteration variable values
\item a list of the final constraint residue values
\item If the run was a scan, the values of the last scan point will be returned.
\end{itemize}

\item{\verb|get_solution_from_outdat(neqns, nvars)|} Returns:-

\begin{itemize}
\item \texttt{ifail}: error value of \process
\item the objective functions
\item the square root of the sum of the squares of the constraints
\item a list of the final iteration variable values
\item a list of the final constraint residue values
\item If the run was a scan, the values of the last scan point will be returned.
\end{itemize}

\end{description}

\subsection{process\_config.py}

A collection of Python classes for configuration files used by various
\process\ utilities, e.g. \texttt{run\_process.py} or
\texttt{test\_process.py}. It contains a base class \texttt{ProcessConfig} and
two derived classes \texttt{RunProcessConfig} and \texttt{TestProcessConfig}.

\begin{description}

\item{\verb|ProcessConfig()|} Object that contains the configuration
  parameters for PROCESS runs.

  \verb|filename| : Configuration file name

  \verb|wdir| : Working directory

  \verb|or_in_dat| : Original \indat\/ file

  \verb|process| : \process\/ binary

  \verb|niter| : (Maximum) number of iterations

  \verb|u_seed| : User specified seed value for the random number generator

  \verb|factor| : Multiplication factor adjusting the range in which the
  original iteration variables should be varied

  \verb|comment| : Additional comment to be written into \verb|README.txt|

\item{\verb|ProcessConfig.echo_base()|} Echos the attributes of the base class
  to standard output.

\item{\verb|ProcessConfig.echo()|} Echos the values of the current class to
  standard output.

\item{\verb|ProcessConfig.prepare_wdir()|} Prepares the work directory for the
  run.

\item{\verb|ProcessConfig.create_readme(directory='.')|} Creates a file called
  \texttt{README.txt} containing \texttt{ProcessConfig.comment}.

\item{\verb|ProcessConfig.modify_in_dat()|} Modifies the original \indat\/
  file.

\item{\verb|ProcessConfig.setup()|} Sets up the program for running.

\item{\verb|ProcessConfig.run_process()|} Runs \process\/ binary.

\item{\verb|ProcessConfig.get_comment()|} Gets the comment line from the
  configuration file.

\item{\verb|ProcessConfig.get_attribute(attributename)|} Gets a class
  attribute from the configuration file.

\item{\verb|ProcessConfig.set_base_attributes()|} Sets the attributes of the
  base class.

\end{description}

\rule{\textwidth}{0.4pt}

\begin{description}

\item{\verb|TestProcessConfig(filename='test_process.conf')|} Object that
  contains the configuration parameter of the \verb|test_process.py| program.

  \verb|ioptimz| : sets \verb|ioptimz| (optimisation solver) in \indat.

  \verb|epsvmc| : sets \verb|epsvmc| (VMCON error tolerance) in \indat.

  \verb|epsfcn| : sets \verb|epsfcn| (finite diff. steplength) in \indat.

  \verb|minmax| : sets \verb|minmax| (figure of merit switch) in \indat.

\item{\verb|TestProcessConfig.echo()|} Echos the values of the current class
  to std out.

\item{\verb|TestProcessConfig.modify_in_dat()|} Modifies \indat\/ using the
  configuration parameters.

\end{description}

\rule{\textwidth}{0.4pt}

\begin{description}

\item{\verb|RunProcessConfig(filename='run_process.conf')|} Configuration
  parameters of the \verb|run_process.py| program.

  \verb|no_allowed_unfeasible| : The number of allowed unfeasible points in a
  sweep

  \verb|create_itervar_diff| : Boolean to indicate the creation of a summary
  file of the iteration variable values at each stage

  \verb|add_ixc| : List of iteration variables to be added to \indat.

  \verb|del_ixc| : List of iteration variables to be deleted from \indat.

  \verb|add_icc| : List of constrained equations to be added to \indat.

  \verb|del_icc| : List of constrained equations to be deleted from \indat.

  \verb|dictvar| : Dictionary mapping variable name to new value (replaces old
  or gets appended)

  \verb|del_var| : List of variables to be deleted from \indat.

\item{\verb|RunProcessConfig.get_attribute_csv_list(attributename)|} Get a
  class attribute list from the configuration file; expects comma separated
  values.

\item{\verb|RunProcessConfig.set_del_var()|} Sets the
  \verb|RunProcessConfig.del_var| attribute from the config file.

\item{\verb|RunProcessConfig.set_dictvar()|} Sets the
  \verb|RunProcessConfig.dictvar| attribute from config file.

\item{\verb|RunProcessConfig.echo()|} Echos the values of the current class.

\item{\verb|RunProcessConfig.modify_in_dat()|} Modifies \indat\/ using the
  configuration parameters.

\item{\verb|RunProcessConfig.modify_vars()|} Modifies \indat\/ by adding,
  deleting and modifiying variables.

\item{\verb|RunProcessConfig.modify_ixc()|} Modifies the array of iteration
  variables in \indat.

\item{\verb|RunProcessConfig.modify_icc()|} Modifies the array of constraint
  equations in \indat.

\end{description}


\subsection{process\_dicts.py}

A collection of dictionaries and lists used by various \process\ utilities.

\begin{description}

\item{\verb|IFAIL_SUCCESS|} This is the \process\ error code of a successful
  run.

\item{\verb|PARAMETER_DEFAULTS|} Default values for making a \plotdat\ file
  from \mfile.

\item{\verb|DICT_VAR_TYPE|} Maps the \process\ variable name to its value
  type. The value type can be one of \verb|int_array|, \verb|int_variable|,
  \verb|real_array| or \verb|real_variable|.

\item{\verb|DICT_IXC_SIMPLE|} Maps the string number of the iteration variable
  to its variable name.

\item{\verb|DICT_IXC_FULL|} Maps the string number of the iteration variable
  to a dictionary that contains the variable name under 'name', the default
  lower variable bound (float) under 'lb' and the default upper variable bound
  (float) under 'ub'.

\item{\verb|DICT_IXC_BOUNDS|} Maps each iteration variable name to a
  dictionary that contains the default lower variable bound (float) under 'lb'
  and the default upper variable bound (float) under 'ub'.

\item{\verb|NON_F_VALUES|} List of iteration variable names that start with an
  f, but are not f-values.

\item{\verb|DICT_NSWEEP2IXC|} Maps the sweep variable number \texttt{nsweep}
  to the respective iteration variable number, if applicable.

\item{\verb|DICT_IX2NSWEEPC|} Maps the iteration variable number to the
  respective sweep variable number \texttt{nsweep}, if applicable.

\item{\verb|DICT_TF_TYPE|} Maps the \process\ TF coil type number to its type.

\item{\verb|DICT_OPTIMISATION_VARS|} Maps each figure of merit number to its
  description.

\item{\verb|DICT_IXC_DEFAULT|} Maps each iteration variable name to its
  default value.

\end{description}

\Red{Add new stuff used by GUI etc.}

\subsection{a\_to\_b\_config.py}

\Red{To do...}

\subsection{proc\_plot\_func.py}

A collection of functions and lists used by \texttt{plot\_proc.py}.

\begin{description}

\item{\verb|RADIAL_BUILD|} A list of radial build variables.

\item{\verb|VERTICAL_BUILD|} A list of vertical build variables.

\item{\verb|FILL_COLS|} A list of plotting colours

\end{description}

For all of the functions below the arguments are:

\hspace{1cm} \texttt{axis} : Matplotlib axis object to plot to

\hspace{1cm} \texttt{mfile\_data} : MFILE data object \verb|MFile|

\hspace{1cm} \texttt{scan} : Scan number to plot

\begin{description}

\item{\verb|plot_plasma(axis, mfile_data,scan)|} Function to plot plasma

\item{\verb|poloidal_cross_section(axis, mfile_data, scan)|} Function to plot machine build

\item{\verb|plot_tf_coils(axis, mfile_data, scan)|} Function to plot the TF coils

\item{\verb|plot_pf_coils(axis, mfile_data, scan)|} Function to plot the PF coils

\item{\verb|plot_geometry_info(axis, mfile_data, scan)|} Function to plot the
  geometry info block

\item{\verb|plot_physics_info(axis, mfile_data, scan)|} Function to plot the
  physics info block

\item{\verb|plot_magnetics_info(axis, mfile_data, scan)|} Function to plot the
  magnetics info block

\item{\verb|plot_power_info(axis, mfile_data, scan)|} Function to plot the
  power info block

\item{\verb|plot_current_drive_info(axis, mfile_data, scan)|} Function to plot
  the current drive info block

\item{\verb|plot_geometry_info(axis, mfile_data, scan)|} Function to plot the
  geometry info block

\end{description}


\subsection{diagnose\_funcs.py}

A collection of functions used by \texttt{diagnose\_process.py}.

\begin{description}

\item{\verb|plot_normalised_ixc(mfilename='MFILE.DAT')|} Plots the normalised values of the iteration variables of a given \mfile.

\item{\verb|plot_normalised_icc_res(mfilename='MFILE.DAT')|} Plots the normalised values of the costraint residuals of a given \mfile.

\end{description}


\section{User Interface}

The user interface is under development more information can be found in the user guide/developer guide.

\begin{thebibliography}{99}
  \raggedright

\bibitem{kovari_physics}
M.\ Kovari, R.\ Kemp, H.\ Lux, P.\ Knight, J.\ Morris, D.\ J.\ Ward
\textit{``PROCESS: a systems code for fusion power plants - Part 1: Physics''},
Fusion Engineering and Design 89, 3054–3069 (2014),
http://dx.doi.org/10.1016/j.fusengdes.2014.09.018

\bibitem{kovari_eng}
M.~Kovari, F.~Fox, C.~Harrington, R.~Kembleton, P.~Knight, H.~Lux, J.~Morris
\textit{``PROCESS: a systems code for fusion power plants - Part 2: Engineering''}, Fus. Eng. \& Des. 104, 9-20 (2016)

\bibitem{hanni_radiation}
H.~Lux, R.~Kemp, D.J.~Ward, M.~Sertoli
\textit{``Impurity radiation in DEMO systems modelling''},
Fus. Eng. \& Des. 101, 42-51 (2015)

\bibitem{Lux2016}
H.~Lux, R.~Kemp, E.~Fable, R.~Wenninger,
\textit{``Radiation and confinement in 0D fusion systems codes''},
 PPCF, 58, 7, 075001 (2016)

\bibitem{WPPMI2014Report}
\textit{``Report on the Systems Code Activities by CCFE in 2014''},
R.\ Kemp, H.\ Lux, J.\ Morris, M.\ Kovari, P.\ Knight et al.,
\href{https://idm.euro-fusion.org/?uid=2M94N2\&version=v1.0\&action=get\_document}
{EuroFusion Report EFDA\_D\_2M94N2 v1.0 - PMI-7.1-2, December 2014}
\url{https://idm.euro-fusion.org/?uid=2M94N2\&version=v1.0\&action=get\_document}



\end{thebibliography}



\end{document}
