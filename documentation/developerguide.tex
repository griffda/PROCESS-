\documentclass[11pt,a4paper]{report}
\usepackage{epsfig,colordvi,latexsym}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{color}
\usepackage{tikz}  %  for VMCON flowchart in Appendix A
\usepackage{url}
\usepackage{hyperref}
\usepackage{framed}
\usetikzlibrary{trees}



\pretolerance=10000
\topmargin=0mm
\headheight=0mm
\headsep=8mm
\textwidth=170mm
\textheight=240mm
\footskip=10mm
\oddsidemargin=0mm
\evensidemargin=-12mm
\parskip=2mm
\parindent=0mm

\setcounter{secnumdepth}{3}
\newcommand{\indat}{\mbox{\texttt{IN.DAT}}}
\newcommand{\mfile}{\mbox{\texttt{MFILE.DAT}}}
\newcommand{\outdat}{\mbox{\texttt{OUT.DAT}}}
\newcommand{\plotdat}{\mbox{\texttt{PLOT.DAT}}}
\newcommand{\process}{\mbox{\texttt{PROCESS}}}
\newcommand{\vmcon}{\mbox{\texttt{VMCON}}}
\renewcommand{\vec}[1]{\boldsymbol{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Add here the date of the latest change and the code revision number
\newcommand{\version}{
15 July 2019
\hfill
PROCESS version: 1.0.16
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\setheader}[1]
 {\markright{\rlap{\lower0.8ex\hbox to\textwidth{\hrulefill}}{\bf#1}}}
\newcommand{\mychapter}[1]{\small\normalsize
 \setcounter{footnote}{0}
 \chapter{#1}
 \pagestyle{myheadings}
 \setheader{Chapter \thechapter\hspace{0.8em}#1}}
\newcommand{\myappendix}[1]{\small\normalsize
 \setcounter{footnote}{0}
 \chapter{#1}
 \pagestyle{myheadings}
 \setheader{Appendix \thechapter\hspace{0.8em}#1}}

\begin{document}

\footnotesize
\hfill

\vspace*{4cm}
\begin{center}
\Huge A Developer Guide\\ to the \\ PROCESS Fusion Reactor Systems Code\\
~\\ \LARGE The PROCESS Team: P.\ J.\ Knight, M.\ D.\ Kovari, H.\ Lux, J.\ Morris, S.\ I.\ Muldrew\\
~\\ \Large Culham Centre for Fusion Energy/ United Kingdom Atomic Energy Authority\\
Culham Science Centre, Abingdon, Oxon, OX14 3DB, UK
\end{center}

\vfill
\footnotesize
\version
\normalsize

\tableofcontents

%\listoffigures

\listoftables

\mychapter{Summary}

This document is describing all aspects of the \process\/ code relevant to developers who add to the \process\/ code. Users who do not edit the \process\/ code do not need to read this document.




\mychapter{Changing the Source Code: New Models, Variables and Constraints}
\label{chap:modify}

It is often useful to add extra features to the code in order to model new
situations. This chapter provides instructions on how to do this, with
specific details on how to add various numerics related items to \process.

Please remember to modify the relevant sections and table(s) in this User
Guide if changes are made to the source code!

\section{Source Code Modification}
\label{sec:codemods}

Described here are the general rules that apply when the Fortran source code
is modified. See Section~\ref{sec:code_release} for instructions on how to
commit changes to the \process\ Git repository and produce new releases. 
The variable descriptor file is generated from specially-formatted comment 
lines within the source code (see Section~\ref{sec:autodoc} for more details). 
Therefore, it is exceedingly important to keep these lines relevant and in 
sync with the variables they describe.

\subsection{Changing the Fortran code}

Please ensure that the following rules are adhered to when modifying the
\process\ source code:

\begin{enumerate}

\item New variables names should be as explicit as possible, even if they tends to get a bit long. More generaly follow the zen of python (you can find it in the following webpage \url{https://www.python.org/dev/peps/pep-0020/}).

\item New routines, sub-routines or functions should be defined with one or several unitarity tests, setup using the pFUnit test suite documented in \url{http://pfunit.sourceforge.net/}.

\item Keep the layout consistent in with the existing code,
  including indentation of clauses (\texttt{if}-statements, \texttt{do}-loops,
  etc.).

\item Use the standard routine header (see below).

\item Always use \verb+implicit none+ and declare all local variables
  explicitly.

\item Declare all `real' (i.e.\ floating-point) variables as
  \texttt{real(kind(1.0D0))}.

\item Ensure all routine arguments have the appropriate attribute \texttt{intent(in)},
  \texttt{intent(out)} or \texttt{intent(inout)}, as necessary.

\item Always write explicit real constants using the scientific \texttt{D}
  notation, e.g.\ \texttt{1.0D0}, \texttt{2.3D0}, \texttt{-1.23D6}. That is to
  say, use \texttt{1.0D0} and not \texttt{1.0} or \texttt{1.} or \texttt{1} when the
  expression should be using floating-point arithmetic.

\end{enumerate}

A Fortran 90/95 manual, complete with guidelines for good Fortran 90/95
practice, may be found at the following webpage:
\begin{center}
\texttt{
\href{http://fusweb1.fusion.ccfe.ac.uk/~pknight/f95notebook.html}
{http://fusweb1.fusion.ccfe.ac.uk/$\sim$pknight/f95notebook.html}
}
\end{center}

\subsection{Source code documentation}

It is critically important to keep the documentation in the source code itself
up-to-date, relevant and tidy. Please keep to the following guidelines
whenever the source code is modified.
\begin{enumerate}

\item Use comments copiously in the code, avoiding useless comments.
	
\item If a used equation is extracted from a published paper, refer explicitly to it,
  citing the paper and equation number when possible (precise the page if no equation number is available, ). 
  For example : \newline
  \texttt{!! Ref eq : J. Johner, Fusion Science and Technology 56 (2011) 308-349, eq(18)}\newline
  For equations taken from the PROCESS user manual, just indicate the page and the paragraph as the equation numbering might change with document updates.
	
\item Use the standard header layout, and do not omit any of the
  sections. Here is an example subprogram header:
\footnotesize
\begin{verbatim}
  ! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

  subroutine culblm(bt,dnbeta,plascur,rminor,betalim)

    !+ad_name  culblm
    !+ad_summ  Beta scaling limit
    !+ad_type  Subroutine
    !+ad_auth  P J Knight, CCFE, Culham Science Centre
    !+ad_cont  N/A
    !+ad_args  bt      : input real :  toroidal B-field on plasma axis (T)
    !+ad_args  dnbeta  : input real :  Troyon-like g coefficient
    !+ad_args  plascur : input real :  plasma current (A)
    !+ad_args  rminor  : input real :  plasma minor axis (m)
    !+ad_args  betalim : output real : beta limit as defined below
    !+ad_desc  This subroutine calculates the beta limit, using
    !+ad_desc  the algorithm documented in AEA FUS 172.
    !+ad_desc  <P>The limit applies to beta defined with respect to the total B-field.
    !+ad_desc  Switch ICULBL determines which components of beta to include (see
    !+ad_desc  routine <A HREF="constraints.html">constraints</A> for coding):
    !+ad_desc  <UL>
    !+ad_desc  <P><LI>If ICULBL = 0, then the limit is applied to the total beta
    !+ad_desc  <P><LI>If ICULBL = 1, then the limit is applied to the thermal beta only
    !+ad_desc  <P><LI>If ICULBL = 2, then the limit is applied to the thermal +
    !+ad_desc                        neutral beam beta components
    !+ad_desc  </UL>
    !+ad_desc  The default value for the g coefficient is DNBETA = 3.5
    !+ad_prob  None
    !+ad_call  None
    !+ad_stat  Okay
    !+ad_docs  AEA FUS 172: Physics Assessment for the European Reactor Study
    !+ad_docs  AEA FUS 251: A User's Guide to the PROCESS Systems Code
    !
    ! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\end{verbatim}
\normalsize
  A description of all the available automatic documentation marker tags
  (these all start with \verb.!+ad_.) may be found by examining the main
  program header of the (self-documenting!) automatic documentation program
  itself (in file \texttt{autodoc.f90}).

\item Ensure that all routines called are listed via
  \verb.!+ad_call. lines.  Update the description lines as necessary. You may
  use html tags and hyperlinks (some are shown in the example above) as
  required; to be sure that they have been added correctly, type \texttt{make
    html} to create the web documentation and examine the relevant html file
  (i.e.\ \texttt{culblm.html} for the example above) using your favourite web
  browser.

\item If you add a new routine to a module, remember to modify the header of the module as well as that of the new routine (add a \verb.!+ad_cont. line to it).

\item Add suitable documentation to this User Guide whenever a
  model is added or modified. This should be done immediately to ensure that
  the Guide remains consistent with the source code. Change the code's revision
  number and the date in \texttt{process.tex}.

\item Add a new file to the folder \texttt{release\_notes}.  It is particularly important to describe here any changes to the required IN.DAT - especially any change that makes previous IN.DAT files unusable.

\end{enumerate}

\section{Input Parameters}

Input parameters (see User-guide) are added to the code in the
following way:

\begin{enumerate}

\item Choose the most relevant module (usually one of those in source file
  \texttt{global\_variables.f90}). Keeping everything in alphabetical order
  (or possibly within a group of variables closely-related to a particular
  switch), add a declaration statement for the new variable, specifying a
  ``sensible'' default value, and a correctly formatted comment line to
  describe the variable. Copy the examples already present, such as
\begin{verbatim}
  !+ad_vars  abktflnc /5.0/ : allowable first wall/blanket neutron
  !+ad_varc                   fluence (MW-yr/m2) (blktmodel=0)
  real(kind(1.0D0)) :: abktflnc = 5.0D0
\end{verbatim}
  Note that the automatic documentation marker tag \verb.!+ad_vars. tells the
  \texttt{autodoc} utility (Section~\ref{sec:autodoc}) that the line is (the
  first line of) a variable description, while \verb.!+ad_varc. specifies any
  continuation lines. Also note that the colon (:) on the first line is
  necessary, as it is assumed to exist by the dictionary-building Python
  utility for the GUI\@.


\item Ensure that all the modules that use the new variable reference the
  relevant module via the Fortran \texttt{use} statement.

\item Add the parameter to routine \texttt{PARSE\_INPUT\_FILE} in source file
  \texttt{input.f90} in a suitable place --- keep to alphabetical order. The
  existing examples provide guidance on how to do this. Note that real (i.e.\
  double precision) and integer variables are treated differently, as are
  scalar quantities and arrays.

\item Input variables names should be as explicit as possible, even if they 
	tends to get a bit long.

\end{enumerate}

\section{Iteration Variables}

The format for defining iteration variables has CHANGED.  These are added in the
same way as input parameters, with the following additions:

\begin{enumerate}

\item The name of an iteration variable must not be more than 14 characters long.
  The variable name should be as be as explicit as possible within this constraint.

\item The parameter \texttt{ipnvars} in module \texttt{numerics} in
  \texttt{numerics.f90} will normally be greater than 
  the actual number of iteration variables, and does not need to be changed.

\item Utilise the next available block of code in module \texttt{define\_iteration\_variables} in 
\texttt{numerics.f90}.

\item Assign values for the variable's lower and upper bounds to the relevant
  elements in arrays \texttt{boundl} and \texttt{boundu}.

\item Paste the variable name in the relevant places in the code block in place 
of the word 'DUMMY'.

\item Ensure that the relevant element of character array \texttt{lablxc} is exactly 14 
characters long.

\item If the variable is declared in a module not listed at the the top of 
\texttt{module define\_iteration\_variables} then it is best to place the required use statement
in the relevant function \texttt{itv\_XX} and subroutine \texttt{set\_itv\_XX)}.
	
\end{enumerate}

It should be noted that iteration variables must not be reset elsewhere in the
code. That is, they may only be assigned new values when originally
initialised (in the relevant module, or in the input file if required), and in
the \texttt{subroutine set\_itv\_XX} where the iteration process itself is performed.
Otherwise, the numerical procedure cannot adjust the value as it requires, and
the program will fail.

\section{Other Global Variables}

This type of variable embraces all those present in the modules in
\texttt{global\_variables.f90} (and some others elsewhere) which do not need
to be given initial values or to be input, as they are calculated within the
code. These should be added to the code in the following way:

\begin{enumerate}
\item The variable name should be as be as explicit as possible.

\item Choose the most relevant module (usually one of those in source file
  \texttt{global\_variables.f90}). Keeping everything in alphabetical order
  (or possibly within a group of variables closely-related to a particular
  switch), add a declaration statement for the new variable, specifying the
  initial value \texttt{0.0D0}, and a correctly formatted comment line to
  describe the variable (copying the examples already present --- see also
  ``Input Parameters'' above).

\item Ensure that all the modules that use the new variable reference the
  relevant module via the Fortran \texttt{use} statement.

\end{enumerate}

\section{Constraint Equations}

Constraint equations (see User-Guide and vardes.html) are added to
\process\ in the following way:

\begin{enumerate}

\item Increment the parameter \texttt{ipeqns} in module \texttt{numerics} in
  source file \texttt{numerics.f90} in order to accommodate the new constraint.

\item Add an additional line to the initialisation of the array \texttt{icc}
  in module \texttt{numerics} in source file \texttt{numerics.f90}.

\item Assign a description of the new constraint to the relevant element of
  array \texttt{lablcc}, in module \texttt{numerics} in source file
  \texttt{numerics.f90}.

\item Add a new Fortran \texttt{case} statement containing the new constraint
  equation to routine \texttt{CONSTRAINT\_EQNS} in source file
  \texttt{constraint\_equations.f90}, ensuring that all the variables used in
  the formula are contained in the modules specified via \texttt{use}
  statements present at the start of this file.  Use a similar formulation to
  that used for the existing constraint equations, remembering that the code
  will try to force \texttt{cc(i)} to be zero.


\end{enumerate}

Remember that if a limit equation is being added, a new f-value iteration
variable may also need to be added to the code.

\section{Figures of Merit}

New figures of merit (see User-Guide and vardes.html) are added to \process\ in
the following way:

\begin{enumerate}

\item Increment the parameter \texttt{ipnfoms} in module \texttt{numerics} in
  source file \texttt{numerics.f90} to accommodate the new figure of merit.

\item Assign a description of the new figure of merit to the relevant element
  of array \texttt{lablmm} in module \texttt{numerics} in source file
  \texttt{numerics.f90}.

\item Add the new figure of merit equation to routine \texttt{FUNFOM} in
  source file \texttt{evaluators.f90}, following the method used in the
  existing examples. The value of \texttt{fc} should be of order unity, so
  select a reasonable scaling factor if necessary. Ensure that all the
  variables used in the new equation are contained in the modules specified
  via \texttt{use} statements present at the start of this file.


\end{enumerate}

\section{Scanning Variables}

Scanning variables (see User-guide and vardes.html) are added to \process\ in
the following way:

\begin{enumerate}

\item Increment the parameter \texttt{ipnscnv} in module \texttt{scan\_module}
  in source file \texttt{scan.f90} to accommodate the new scanning variable.

\item Add a short description of the new scanning variable to the
  \texttt{nsweep} entry in source file \texttt{scan.f90}.

\item Add a new assignment to the relevant part of routine \texttt{SCAN} in
  source file \texttt{scan.f90}, following the examples already present,
  including the inclusion of a short description of the new scanning variable
  in variable \texttt{xlabel}.

\item Ensure that the scanning variable used in the assignment is contained in
  one of the modules specified via \texttt{use} statements present at the
  start of this routine.

\end{enumerate}

\section{Submission of New Models}

The \process\ source code is maintained by CCFE, and resides in a
\textit{Git}~\cite{git} repository on the CCFE servers. We welcome
contributions of alternative or improved models and algorithms.

We request that contributors provide the following information for any new models that they provide:

\begin{itemize}
	
\item The name of the fortran files should be as explicit as possible and in agreement with the GUI structure. The following convention should be used: \texttt{moduleName.f90}, with \texttt{moduleName} being the name used in the GUI. If several \texttt{.f90} files are associated to one GUI module, identify the main \texttt{.f90} file, and name the other files \texttt{moduleName\_libName.f90} with \texttt{libName} being the chosen name for the library.

\item A comprehensive description of the model; please provide a full list of
  references.

\item A list of all inputs and outputs: descriptions, default (input) values,
  allowed ranges, units.

\item If possible, please cross-reference any input/output variables to
  existing global variables listed in the variable descriptor file (see User-guide and vardes.html).

\item Any new input parameters, iteration variables, constraint equations, figures of merit etc.

\item A definition of any pre-requisites.

\item  As many unitary test should be defined as possible, using the pFUnit test suite documented in \url{http://pfunit.sourceforge.net/}.

\item Any available test data, code examples or test programs in any language.

\end{itemize}



\section{Code Structure}
\label{sec:code_structure}

\subsection{Directory structure}
\label{sec:dir_structure}

The folder structure for the PROCESS system prior to compilation is described below:


\begin{quote}
	\begin{verbatim}
*-- CMakeLists.txt                      : Build and compile files
*-- GNUmakefile                         : Build and compile pFUnit files
+-- lib                             : Libraries used in PROCESS
|   +-- PLASMOD                         : PLASMOD lib files
+-- source                          : source files
|   +-- Fortran                         : Fortran source files
|   +-- cpp                             : C++ source files
+-- test_suite
|   *-- ci_test_suite.py                : Python file for running test suite in Continuous integration system
|   *-- ci_test_suite_functions.py      : Python functions  for running test suite in Continuous integration system
|   *-- test_suite.py                   : Python file for running test suite by user on command line
|   *-- test_suite_functions.py         : Python functions  for running test suite by user on command line
|   +-- test_files                      : Input files for test suite
|   +-- test_area                       : Output files for test suite
+-- unit_tests
|   +-- pfunit_files                    : pFUnit test files
|   +-- gtest_files                     : GTest test files
+-- utilities/                          : Python utilities files
+-- fispact/                                : fispact Data file
+-- data                                : Data files
|   +-- fluids
|   +-- h_data
|   +-- lz_non_corona
|   +-- lz_non_corona_14_elements
+-- documentation                       : Contain documentation files
	\end{verbatim}
\end{quote}

\subsection{Numerics modules}
\label{sec:numerics_modules}

These modules contain the equation solvers, their calling routines and other
relevant procedures. Various mathematical routines from a number of standard
libraries are also incorporated into these files. Table~\ref{tab:numerics}
summarises the numerics source files.

% Table summarising numerics modules in PROCESS
\begin{table}[tbph]
\footnotesize
\begin{center}
\begin{tabular}{||l||l||} 
\hline
source file   & description \\ 
\hline
\texttt{caller.f90}                & calls physics, engineering, building and cost routines \\
\texttt{constraint\_equations.f90} & defines the constraint equations \\
\texttt{evaluators.f90}            & function evaluators for HYBRD and \vmcon\ packages \\
\texttt{iteration\_variables.f90}  & adjusts values of iteration variables \\
\texttt{maths\_library.f90}        & miscellaneous `black-box' maths routines,
including HYBRD and \vmcon \\
\texttt{numerics.f90}              & numerics array definitions, and calling routines for
HYBRD and \vmcon\ packages \\
\texttt{quanc8.f90}                & 8 pannel newton cotes integration function \\
\texttt{scan.f90}                  & performs a parameter scan \\
\hline
\end{tabular}
\end{center}
\caption[Summary of numerics modules]
{\label{tab:numerics}
  \textit{Summary of the numerics modules in \process.}
}
\end{table}

\subsection{Physics modules}

These modules contain the main physics routines that evaluate the plasma and
fusion parameters. Also included here are the routines describing the current
drive and divertor systems. Table~\ref{tab:physics} summarises the main physics
source files.

% Table summarising physics modules in PROCESS
\begin{table}[tbph]
\begin{center}

\begin{tabular}{||l||l||} 
	\hline
source file                          & description \\
	\hline
\texttt{current\_drive.f90}          & current drive efficiency calculations \\
\texttt{divertor.f90}                & Kukushkin/Harrison divertor model     \\
\texttt{divertor$\_$ode.f90}         & Kallenbach divertor model (1D) \\
\texttt{fispact.f90}                 & nuclide inventory/activation calculations \\
\texttt{hare.f90}                    & ECCD current drive using HARE \\
\texttt{ife.f90}                     & Inertial Fusion relevant physics/engineering \\
\texttt{impurity\_radiation.f90}     & radiation power calculations \\
\texttt{physics.f90}                 & tokamak plasma and fusion calculations \\
\texttt{physics$\_$functions.f90}    & plasma physics parameters calculation called by \\
                                     & \texttt{physics$\_$functions.f90}, \texttt{stellarator.f90} and \texttt{plasmod.f90}\\
\texttt{plasma\_geometry.f90}        & plasma geometry algorithms \\
\texttt{plasma\_profiles.f90}        & plasma density and temperature profile calculations \\
\texttt{plasmod.f90}                 & interface with the PLASMOD transport code\\                                     
\texttt{reinke$\_$module.f90}        & Reinke minimum impurity fraction for divertor protection calculation \\                                                    
\texttt{startup.f90}                 & plasma start-up auxiliary power requirements \\
\texttt{stellarator.f90}             & stellarator-relevant physics/engineering \\
	\hline
\end{tabular}
\end{center}
\caption[Summary of physics modules]
{\label{tab:physics}
  \textit{Summary of the physics modules in \process.}
}
\end{table}

\subsection{Engineering modules}

These modules contain the description of the machine geometry and its major
systems, including the PF and TF coil sets, the first wall, blanket and
shield, and other items such as the buildings, vacuum system, power conversion
and the structural components.  Table~\ref{tab:engineering} summarises the main
engineering source files.

% Table summarising engineering modules in PROCESS
\begin{table}[tbph]
\begin{center}

\begin{tabular}{||l||l||}
	\hline
source file     & description \\ 
	\hline
\texttt{availability.f90}   	 & Plant component lifetimes and overall availability \\
\texttt{buildings.f90}      	 & Buildings calculations \\
\texttt{fw.f90}             	 & First wall calculations \\
\texttt{hcpb.f90}           	 & HCPB blanket and shield calculations \\
\texttt{hcll.f90}           	 & HCLL blanket and shield calculations \\
\texttt{machine\_build.f90} 	 & Machine build calculations \\
\texttt{pfcoil.f90}         	 & PF coil module \\
\texttt{plant\_power.f90}        & Heat transport and power balance calculations \\
\texttt{pulse.f90}               & Pulsed power plant calculations \\
\texttt{safety.f90}              & Steady-state temperatures after a LOCA event \\
\texttt{sctfcoil.f90}            & Superconducting TF coil module\\
\texttt{stellarator$\_$fwbs.f90} & Stellarator HCPB breeding blankets \\
\texttt{structure.f90}      	 & Support structure calculations \\
\texttt{superconductors.f90}     & Supraconductor properties \\
\texttt{tfcoil.f90}              & Resistive TF coil module \\
\texttt{vacuum.f90}        		 & Vacuum system calculations \\
	\hline
\end{tabular}
\end{center}
\caption[Summary of engineering modules]
{\label{tab:engineering}
  \textit{Summary of the engineering modules in \process.}
}
\end{table}

\subsection{Costing module}
Three cost models are available:
\begin{itemize}
	\item the 1990 one contained in \texttt{costs.f90} performs all the cost calculations, 
		including values in M\$ for each machine system, and the cost of electricity
		in m\$/kWh. Normally, the machine costs are written to the output file; if
		this is not required set switch \texttt{output\_costs = 0}. 
	\item The Kovari 2015 one, contained in \texttt{costs$\_$2015.f90}, provides only the capital cost.
	\item A new cost model under development in \texttt{costs$\_$step.f90}
\end{itemize}


\subsection{Specific modules libraries}

Several modules are only called by specific modules to load dedicated physical data or mathematical tools. Here a list of theses modules loaded by:
\begin{itemize}
	\item Hare module : \texttt{currn.f90}, \texttt{TorGA\_curgap.f90} and \texttt{green\_func\_ext.f90}
	\item Kallenbach module : \texttt{kallenbach\_module.f90} (testing libraries), \texttt{read\_and\_get\_atomic\_data.f90},\ \texttt{read\_radiation.f90}
	\item Reinke module : \texttt{read\_radiation.f90}
	\item Supraconductor TF module : \texttt{ode.f90}
\end{itemize}


\subsection{Other modules}
These modules perform miscellaneous tasks, such as initialisation of variables
and file input / output. File \texttt{process.f90} contains the main program,
and includes the overall controlling loop.

Table~\ref{tab:other_modules} summarises these modules.

% Table summarising miscellaneous modules in PROCESS
\begin{table}[tbph]
\begin{center}

\begin{tabular}{||l||l||}
	\hline
source file     & description \\ 
	\hline
	
\texttt{autodoc.f90}           & Automatic html \texttt{PROCESS} documentation generation \\
\texttt{error\_handling.f90}   & centralised error handling module \\
\texttt{fson\_library.f90}     & library used to read in data from JSON-format files \\
\texttt{global\_variables.f90} & defines and initialises most shared variables \\
\texttt{initial.f90}           & checks self-consistency of input variables and switches \\
\texttt{input.f90}             & reads in user-defined settings from input file \\
\texttt{output.f90}            & utility routines to format output to file \\
\texttt{process.f90}           & main program and top-level calling routines \\
	\hline
\end{tabular}
\end{center}
\caption[Summary of other modules]
{\label{tab:other_modules}
  \textit{Summary of the remaining modules in \process.}
}
\end{table}

\mychapter{Code Management Tools}
\label{chap:codetools}

This chapter will be of interest to people involved in the continuing 
maintenance of the \process\ source code. As stated elsewhere, the source code
is maintained by CCFE, and resides in a Git repository on the CCFE servers.


\section{Initial access to the source code}
\label{sec:getsource}

To gain access to the \process\ source code Git repository, you need
to be given permission to do so via the CCFE \texttt{GitLab} server.
\begin{enumerate}
	
	\item Use a web browser to go to
	\href{http://git.ccfe.ac.uk}{\texttt{http://git.ccfe.ac.uk}}
	
	\item Login using your normal CCFE computer login details.
	
	\item Assuming this is successful, contact the \texttt{GitLab} \process\
	``Owner'' (currently James Morris james.morris2@ukaea.uk), who will add you to \texttt{GitLab} as a \process\ ``Developer''.
	
	\item If this is your first access to \texttt{GitLab}, you may have to set up
	SSH keys. To do so, get back to \url{https://git.ccfe.ac.uk/} and click on your
	profile on the top right corner, it will show a menu where you will have to click on
	setting. On the left menu then click on SSH Keys and simply follow the instructions.
	
	click on on your profile picture 
	
	\item Login to a Fusion Unix Network machine.
	
	\item \texttt{cd SomewhereAppropriate} (you choose!)
	
	\item
	\texttt{git clone git@git.ccfe.ac.uk:process/process.git -b develop my\_develop}
	This copies the \texttt{develop} branch of the repository into a local folder \texttt{my\_develop}, which will be created if it does not already exist.
	\item \texttt{cd my\_develop}
	
	\item \texttt{git checkout develop}
	
	The sequence of commands above will provide you with a full copy of the \texttt{develop} branch of the \process\ source code, Python utilities and all
	the documentation files.
	
\end{enumerate}


\section{Environment set-up}
\label{sec:run_environment_dev}

Please note that this section is only relevant for people actually developing the \process\  code, i.e. if you are interested in running a copy of the code from your local directory on the fusion Unix network. For normal users please refer to the User-guide.

To compile \process\ you must simply have:
\begin{itemize}
	\item \texttt{gfortran} to compile the main \process\ souces. The compilation will not work with ifort
	\item \texttt{gcc} to compile the \process\ GUI
	\item \texttt{python} to run the \process\ utilities.
\end{itemize}

If you are developing from the Freia CCFE cluster, please use the following commands to setup the environment for compilation and documentation generation:
\begin{quote}
	\begin{verbatim}	
	module unload ifort
	module unload pgi
	module load gfortran
	module load texlive/2017
	\end{verbatim}
\end{quote}

It can be convenient to add the following lines to your \texttt{.bashrc} file\footnote{ This is a file in the user's home directory, assuming the bash Unix shell is being used. Although hidden, it can be opened by issuing the relevant command, for example \texttt{gedit .bashrc}.}, to avoid retyping them for each compilations.\newline

If you are working from your local machine, you will have potentially to install the gcc and gfortran compilers manually. You will also have to install cmake and the google profiling software. For Linux Ubuntu users, it can be simply done using:

\begin{quote}
	\begin{verbatim}
	sudo apt-get install gfortram
	sudo apt-get install gcc
	sudo apt-get install cmake
	sudo apt-get install googletest
	sudo apt-get install pdflatex
	sudo apt-get install bibtex
	\end{verbatim}
\end{quote}

Additional steps must be followed to install google test. Please gently ask J. Morris for this, he is the one!


\section{The CMakefile}
\label{sec:makefile}

To improve the portability of the \process\ code to different operating systems (Linux, Windows or Mac), its compilation is now done using cmake. The compilation, html code documentation, pdf manual generation, unitary test and profiling instructions are contained in the \texttt{CMakeLists.txt} file. This has proved to be of great benefit in keeping all of the data from a given run together for archival purposes. Different verbosity level options can be set.

\subsection{Compilation}

The compilation on the Freia cluster can be done using CMake, with the following commands:

\begin{quote}
	\begin{verbatim}
	cmake3 -H. -Bbuild
	cmake3 --build build
	\end{verbatim}
\end{quote}

The first cmake command creates the folder and setup the compilation options, the second triggers the actual \process\ compilation. At the end of the compilation, a binary files folder \texttt{bin/} is created containing two executables \texttt{process.exe}, \texttt{process\_GTest.exe} allowing to run the \process\ code and its unitarity test, respectively and a sheared object (\texttt{.so}, called DDL in the windows environment), containing most of the \process\ code.\newline
	
To show all compiler warnings (\texttt{ -Wall} and \texttt{-Wextra}), add the \texttt{-Ddebug=ON} option flag to the first cmake command. To allow unitary tests on functions using local fortran variables, the \process\ code is compiled as a DLL (Dynamic Linl Libraries, \texttt{.so} files in C++). It can nevertheless be compiled as a single executable, adding the \texttt{-Ddll=OFF} option to the first cmake command.\newline

Several options on the second cmake command (\textcolor{gray}{}) can be used to:
\begin{itemize}
	\item Generate the python dictionaries: \texttt{--target dicts}
	\item Generate the pdf documentation: \texttt{--target doc}.
	\item Generate the html documentation: \texttt{--target html}.
\end{itemize}
To clean build directory, simply remove it:
\begin{quote}
	\begin{verbatim}
	rm -fr build 
	\end{verbatim}
\end{quote}
	
If the build is done on your local machine, use the same instruction replacing \texttt{cmake} by \texttt{cmake}\footnote{cmake3 is an alias used on the Freia cluster to precise the cmake version (3)}.\newline


%\subsection{\textcolor{gray}{Archiving utilities}}

%\textcolor{gray}{The makefile can be used in a number of ways to pack the various file sets
%together into a single compressed tar file, for ease of portability and
%archiving.}

%\begin{itemize}

%\item \textcolor{gray}{\texttt{make tar}: Typing this command produces a file
%  \texttt{process.tar.gz} that contains all of the source files, utility
%  programs and documentation files necessary to run the program from scratch
%  on a new machine or in a new directory. (Note that the input files \indat\
%  and \texttt{device.dat} are not included.) This is useful for transferring
%  new copies of source files, etc.\ into an existing directory already
%  containing a previous \process\ run, as the pre-existing customised input
%  files will not be overwritten. To extract the individual files again, copy
%  the file to the destination working directory and type}
%  \verb+tar zxvf process.tar.gz+

%\item \textcolor{gray}{\texttt{make archive}: Typing this command produces a file
%  \texttt{process\_run.tar.gz} containing the working directory's input and
%  output files (\indat, \outdat, \plotdat, \mfile\ and \texttt{device.dat}
%  (which must exist to avoid an error message; see Section~\ref{sec:device}),
%  together with all of the source files, utility programs and documentation
%  files. These files together comprise the full set that define a given run,
%  and so the file produced by this command is suitable for long-term storage
%  for archival purposes. To extract the contents, type}
%  \verb+tar zxvf process_run.tar.gz+
%\end{itemize}

%\textcolor{gray}{Note that each of the above commands will overwrite the given named tar file
%if one already exists in the working directory.}

\subsection{Automatic Documentation}
\label{sec:autodoc}

The \process\ source code is self-documenting to a degree, using an included
parser program (\texttt{autodoc}) to generate html files for each subprogram
from specially-formatted comment lines within the code. It is the
responsibility of the programmer to keep the \texttt{autodoc} comments within
the source code relevant, comprehensive and up-to-date! Use the examples in
the code as a starting basis for new routines; the output section
corresponding to the various \texttt{autodoc} tags should be
self-explanatory. See also Section~\ref{sec:codemods}.

The following files are used:

\begin{quote}
	\begin{verbatim}
	autodoc.f90
	adheader.src
	adfooter.src
	\end{verbatim}
\end{quote}


To create the ($\sim 526$) html files from the source code, type

\begin{quote}
	\begin{verbatim}
	cmake3 --build build --target html
	\end{verbatim}
\end{quote}

This command will fill the following directory \texttt{documentation/html/} with one html file per fortran source code contained in \texttt{source/fortran} directory. Any html file can be opened by your favourite web browser. For example, to open the documentation of the main \process\ function just use

\begin{quote}
	\begin{verbatim}
	cd documentation/html
	firefox process.html
	\end{verbatim}
\end{quote}

\subsection{\LaTeX\ documentation}
\label{sec:tex_doc}

In addition, a full \LaTeX\ documentation is and have to be maintained by the \process\ developpers:
\begin{itemize}
	\item A user guide contained within \texttt{process.tex}
	\item A developper guide contained within \texttt{developerguide.tex}
	\item A description of the \process\ solvers contained within \texttt{optsolverdoc.tex}
	\item A description of the \process\ magnets modules contained within \texttt{optsolverdoc.tex}
	\item A description of the \process\ python utilities contained within \texttt{utilitiesdoc.tex}
\end{itemize}

To generate the .pdf files, simply execute the following command:

\begin{quote}
	\begin{verbatim}
		cmake3 --build build --target doc
	\end{verbatim}
\end{quote}

All these files must be maintained in strict agreement with the evolution of the \process\ code. It is the developper responsability to update them when a change is commited in the different source codes.


\subsection{Unitary test}
A fortran unitarity test framework pFUnit, is implemented in the \process\ code. A documentation of this tool is available in \url{http://pfunit.sourceforge.net/}. The unitary test are configured using \texttt{*.pf} files contained in the \texttt{test\_files/pfunit\_files/} folder. The unitarity test are executed using: 

\begin{quote}
	\begin{verbatim}
	cmake3 --build build --target test-build
	\end{verbatim}
\end{quote}
\textcolor{red}{IS THE COMMAND RIGHT ??}


\section{Code Updates and Release Procedure}
\label{sec:code_release}

This section describes the procedures that should be followed whenever new
commits to the \texttt{develop} or \texttt{master} branches of the \process\
Git repository are to be made, and how new code releases are performed. It is
assumed that readers have a working knowledge of Git commands.


\subsection{Git workflow}
The code management methodology is based on the so-called
\href{https://www.atlassian.com/git/workflows#!workflow-gitflow}{``gitflow''}
workflow. There are two main branches:
\begin{itemize}
	
	\item \texttt{develop}, which is the basis for all code development work, and
	changes are committed to it frequently.
	
	\item \texttt{master}, which contains official ``release'' versions of
	\process, and is updated on a roughly three-monthly timescale.
	
\end{itemize}

Development work on new models should use separate branches, named e.g.\
\texttt{dev\_mynewmodel}, split from the \texttt{develop} branch. It is a very
good idea to merge the \texttt{develop} branch into \texttt{dev\_mynewmodel}
frequently during the course of the work, so that changes to the main branch
are transferred to the new model's files with minimal effort.

Once the new model has been finished and tested successfully (complete with full
documentation --- see Section~\ref{sec:codemods}), the branch should be merged
back into the \texttt{develop} branch.

\Red{Note that typically development branches do not need version tagging as they should not be used in any production runs. However, e.g. for the DEMO baseline design a separate branch will be created to conserve the \process\/ output in the state when the baseline was fixed.}



\subsection{Tagging}
\label{sec:tagging}

Tagging in \process\/ is used to document the version of the code any individual
run has been performed with. This is necessary for proper provenance capture.
Any version produced after 2016 takes the form x.y.z for internal development versions and takes the form x.y for external master releases:

\begin{center}
	[major version].[minor version].[revision number]
\end{center}
with 
\begin{itemize}
	\item $[$major version$]$ - release containing numerous major changes
	\item $[$minor version$]$ - medium change, i.e. new model, major bug fix
	\item $[$revision number$]$ - weekly or on demand build/change 
\end{itemize}

Any development versions ending in .0 should be fully tested as they correspond to the public ones. For example the version 2.4 of the master version must corresponds to the 2.4.0 of the development version.


\subsubsection{Tagging in a separate branch}
This section covers tagging in e.g. the separate DEMO1 baseline branch and assures that while this branch can develop independently of the development branch, it still has unique version tagging and provenance capture. Tagging of a separate branch should be started when it is forked from develop. Hence, the initial tag should be 

\begin{center}
	[BID]\_[major version].[minor version].[revision number]
\end{center}
where [BID] is a short but informative branch identifier consisting of letters only. This allows for branching from the development version at any point. Ideally it does start from a fully tested version though!\newline
\textcolor{red}{Manoj, please check that both characters as well as the new dot format are possible options for the autodoc tool!}

\subsubsection{Tagging between manual tags}
Between user tags Git will create tags in the following format:

\texttt{1.0.12-11-g3f1b433}

The parts are:
\begin{itemize}
  \item \texttt{1.0.12} is the last manually entered tag by the user
  \item \texttt{11} is the number of commits since that tag
  \item \texttt{g3f1b433} is a unique identifier for this specific commit
\end{itemize}

This allows the user to checkout a specific commit between tagged versions.
PROCESS now outputs this information into the `OUT.DAT` and `MFILE.DAT` and is
updated upon compilation. This way each output file is trackable to a specific commit.

\subsection{Git manipulations}

The git manipulations can be made with command lines or through the VS code editor that proposes many convenient features for Git. The VS code editor can be downloaded at \url{https://code.visualstudio.com/} for any platforms. Many extensions are available, we strongly recommand to unstall the fortran, C++, python, cmake and latex one are these languages are used in \process.

\subsubsection{Commit logs}
To see the commit messages you can use the \texttt{git log} command. There are various options
described in table~\ref{tab:commit_log}:


\begin{table}[tbph]
	%\footnotesize
	\begin{center}
		\begin{tabular}{@{}lll}
			\hline \hline
			\textbf{Command}                     & \textbf{Description}                     & \textbf{Example}           \\
			\hline
			\texttt{-(n)}                        & show the last \texttt{n} commits         & \texttt{git log -5}                 \\	
			\texttt{--since} or \texttt{--after} & limits the logs to be from date given    & \texttt{git log --since "21-01-15"} \\	
	               		                         & can use \texttt{number.scale} where      & \texttt{git log --since 2.weeks}    \\
	               		                         & scale=year/month/week/day/minute         & \\	
			\texttt{--until} or \texttt{--before}& limits the logs to be up to date given   & \texttt{git log --until "22-01-15"} \\	
			\texttt{--author}                    & only shows commits from given author     & \texttt{git log --author "morrisj"} \\	
			\texttt{--grep}                      & only show commits with a commit          & \texttt{git log --grep "magnet"}    \\
		                                         & message containing the string given      & \\	
			\texttt{--stat}                      & if you want to see some abbreviated      & \texttt{git log --stat}             \\
			                                     & stats for each commit                    & \\
			\texttt{--oneline}                   & Outputs commit number, date and          & \texttt{git log --oneline}          \\
			                                     &  message to a single line                & \\ 	
			\texttt{--graph}                     & display commits in a ASCI graph          & \texttt{git log --graph} \\	
			\texttt{-S}                          & only show commits adding or removing     & \texttt{git log -S "find\_me"} \\
			                                     & code matching the string                 & \\
			\hline \hline
		\end{tabular}\\
		\caption{\label{tab:commit_log} \texttt{git log} option description.}
	\end{center}
\end{table}

\subsubsection{Branching from \texttt{develop}}

The following commands create a new branch in which to work on a new model. We
assume that you are already in the \texttt{process} directory created above
(Section~\ref{sec:getsource}).
\begin{enumerate}

\item \texttt{git checkout develop} : to ensure that this is the branch
      \textit{from which}\/ you will be branching.

\item \texttt{git branch dev\_mynewmodel} : Creates an empty local branch called \texttt{dev\_mynewmodel}.

\item \texttt{git checkout dev\_mynewmodel} : load the branch that has been checked out in
      the \texttt{dev\_mynewmodel} branch. This is a \textit{local} manipulation.

\item \texttt{git push origin HEAD} : updates the central \texttt{GitLab} repository. The
      created branch will appear in the \process\ Git webpage 

\end{enumerate}

\subsubsection{Working on a new model}

Edit your local copies of the files as necessary. A convenient free editor is Visual Studio (\url{https://visualstudio.microsoft.com}) as it has handful integrated Git property (easy commit, easy diff, integrated grep command etc..). Whenever you want to save the changes 
back to the repository. It is prudent to do this at the end of each working day, as well
as when the changes are complete, the code compiles and all test runs are successful. To
perform a user commit, use the following commands:
\begin{enumerate}

\item \texttt{git status}  (this will show a list of modified files)

\item \texttt{git add changedfile1 changedfile2 ...}  \\
  (This `stages' the modified files marking them as ready for committing).  \\
  \texttt{git commit}

  Alternatively, just use\\
  \texttt{git commit -a} \\
  This commits all modified tracked files.

\item An editor window will open; add a line summarising the changes you have made, save and close the window. (Do not use quotation markes in your message.) This will initiate the commit to your \textit{local}\ copy of the repository.

\item An alternative is to type\\
\texttt{git commit -a -m 'Type message here'} \\
This commits all modified tracked files, and adds the message entered between single quotes as shown.  No editor will open.  Do not use any quotation marks inside the message.

\item \texttt{git push} \\
Copies the changes you have made locally to the version in the central \texttt{GitLab} repository.  This uses a merging process, but if no-one else has changed your branch then the central version will simply become a copy of your local version.
\end{enumerate}

If VS is used as text editor it much more convenient to do:
\begin{enumerate}
	\item Go to Source Control clicking the corresponding icon on the left panel (a Y with three empty circles on the ends) or using the following shortcut \texttt{Ctrl-Shift-G}. 
	On the left panel will appear the list of all the files that :
	\begin{itemize}
		\item has been modified since the last committed version with a \textcolor{olive}{M} sign on the right of the filename,
		\item has been added but untracked by Git with a \textcolor{gray}{U} sign
		\item has been added and taken into account by the Git repository with a \textcolor{cyan}{A} sign.
	\end{itemize}
	
	\item You can have a look at the differences of the modified files simply clicking on it on the list, it will show a dual text editor with on the left the last committed version and on the right the current file version, highlighting all the difference between the two!
	
	\item Commit the file version to your branch. For this simply do
	\begin{itemize}
		\item Verify if all the changes you made are compiling and executing flawlessly with meaningful physical result
		\item Write a detailed and explicit description of the chances you are about to commit
		\item Point your mouse on the file you want to commit and click on the + sign that appears to select the file you want to commit.
		\item Use the \texttt{Ctrl+Enter} shortcut to commit.
	\end{itemize}
	
	\item Update your branch is the common \process\ repository (\process\ Git webpage) using \texttt{git push --set-upstream origin dev\_mynewmodel}, with \texttt{dev\_mynewmodel} being the name of your developing branch.
\end{enumerate}



\subsubsection{Merging \texttt{develop} into working branch}

It is a good idea to periodically merge the \texttt{develop} branch into the branch in which you are working, to ensure that any changes made in \texttt{develop} are included in your working branch.
\begin{enumerate}

\item Firstly, make sure you have committed your latest changes into the
  central \texttt{GitLab} repository as described in the previous section.  Set the directory containing the working branch as your current directory.

\item \texttt{git pull}.  \\
Merges the version in the central repository into the local branch by copying over any changes that have been made in the version stored centrally.

\item \texttt{git checkout develop}  \\
This switches the "current branch" to \texttt{develop}.

\item \texttt{git pull} \\
Updates the current branch of the local repository to the same branch on the central repository.

\item \texttt{git checkout dev\_mynewmodel}  \\
This switches the "current branch" to \texttt{dev\_mynewmodel}.

\item \texttt{git merge develop} \\
Merges \texttt{develop} into the \texttt{dev\_mynewmodel} branch.

\item Look for messages on the screen containing the word "conflict" indicating that some files cannot be merged directly. This typically happens if the
  same (or very closely-spaced) lines have been edited in both the
  \texttt{develop} and \texttt{dev\_mynewmodel} branches.

  If any files are affected, they will be listed.  Edit them and look for any lines containing  \texttt{=======}. Such lines separate the changes made in the two branches, as in:
\begin{verbatim}
<<<<<<< HEAD
This line was edited in dev_mynewmodel branch
=======
This line was edited in develop branch
>>>>>>> develop
\end{verbatim}
  Resolve the conflict(s) as necessary. Then type \texttt{git add file1 file2 ...}, where
  \texttt{file1} etc.\ are the names of the files you removed conflicts
  from. Finally type \texttt{git commit} and edit the change log file.

\item \texttt{git push}: Update the central repository.

\end{enumerate}


\subsubsection{Committing changes to \texttt{develop}}

Whenever a commit to the \texttt{develop} branch is to be made, the following
procedure should be followed. Ensure all documentation is up to date (see
Section~\ref{sec:codemods}) and the code is fully tested.
\begin{enumerate}

\item In routine \texttt{inform} of file \texttt{process.f90}, change the
  definition of \texttt{progver} by incrementing the \Red{last digit of the revision number by one e.g. from \texttt{1.3.26} to \texttt{1.3.27} for each minor commit or the second git for each fully tested major model that is included while setting the last digit to 0 e.g. from \texttt{1.3.26} to \texttt{1.4.0}}. Furthermore, update the Release Date. It is important to keep exactly the same format.

\item Add a brief comment to the bottom of source file \texttt{process.f90}
  describing the changes made since the last commit in the same branch. Start
  the line with \texttt{! GIT XYZ: }, following the existing examples.

\item If any of the User Guide \texttt{.tex} files have been modified, edit
  the definition of \verb+\version+ in \texttt{process.tex} by changing the
  Revision \Red{(to e.g. \texttt{1.3.27})} and the date.

\item If you have changed any "use" statements in the code, or any compilation dependencies in the Makefile, run \\
\texttt{make clean}

\item Check the code compilation and the html code documentation in a verbose mode
\begin{center}
	\begin{verbatim}
	cmake3 -H. -Bbuild -Ddebug=ON
	cmake3 --build buid --target html
	cmake --build buid
	\end{verbatim}
\end{center}

\item Run the input file(s) in the \texttt{tests} folder to ensure PROCESS runs correctly.

\item Close all opened editor windows. The commit will not work otherwise.

\item   \texttt{git commit -a -m 'Type your message here'} \\
  This commits all modified tracked files. (Do not use quotation marks inside your message.)\\
  \\
  Alternatively, you can do this in two steps:\\
  \texttt{git add process.f90 process.tex changedfile1 changedfile2 ...}  \\
  (This `stages' the modified files marking them as ready for committing).  \\
  \texttt{git commit}

\item An editor window will open; add a line summarising the changes you have made.  Use a format like this:
\begin{verbatim}
1.3.27   A summary of the changes made
Further details. Changes due to Git issues can be described like this:
#270    Description
#273    Description
\end{verbatim}
Save and close the window. This will initiate the commit to your \textit{local}\ copy of the repository.

\item \texttt{git tag -a 1.3.27 -m `Revision 1.3.27'}

\item \texttt{git push}

\item \texttt{git push origin 1.3.27}

\end{enumerate}

The instructions given in Section~\ref{sec:fullrebuild} should now be followed to make the new \texttt{develop} release available to all users.

\subsubsection{Merging develop into master}

\Red{When merging develop into master, please note that the tagging changes as described in section \ref{sec:tagging}.}

\subsection{Full code rebuild}
\label{sec:fullrebuild}

The standard \process\ executables and the corresponding documentation
available to all users are stored in the functional account called
\texttt{PROCESS} on the CCFE Fusion Unix Network. Whenever the \texttt{master}
or \texttt{develop} branches are updated a full rebuild of the standard
executables and documentation should be performed. This is done as follows:
\begin{enumerate}

\item Ensure that all key users have been informed (using the commit message described above or directly).

\item \texttt{alter PROCESS}  (this changes your current login to that of the
  \texttt{PROCESS} user; only registered individuals are able to do this)

\item \texttt{cd develop}  (or \texttt{cd master}, as appropriate to the
  branch to be rebuilt)

\item \texttt{git pull}\\
Updates the version stored in this folder to the version stored centrally.

\item Re-compile the code. This is essential because the Git repository does not include any of the files generated in the compilation process.
\begin{center}
	\begin{verbatim}
	cmake3 -H. -Bbuild
	cmake3 --build buid
	\end{verbatim}
\end{center}

\item \texttt{exit}  (to return to your own username again)

\end{enumerate}

The \texttt{cmake} steps performs the rebuild of the \texttt{process.exe} executable
file, updates the User Guide and all the html files, and recreates the Python
dictionaries as required by the Python utilities.


\mychapter{Graphical User Interface}
To currently use the \process GUI, go through the following steps. This only works if you have at least reporter access on the project.

\begin{enumerate}
\item    Clone \texttt{Home} branch from the Gitlab.   \texttt{git clone --branch home git@git.ccfe.ac.uk:mkumar/PROCESS\_GUI.git folder\_name} . If \texttt{folder\_name} is not typed then it will create a folder \texttt{PROCESS\_GUI} and clone source code there.

\item    Go to folder with source code where you will find a number of directory. Issue command   \texttt{qmake-qt5 PROCESS\_GUI.pro}  , which will generate Makefile for compilation.

\item After successful step 2, issue command \texttt{make}. This will initiate compilation and save executable to a folder called \texttt{bin}.

\item    After successful step 3, go to folder called \texttt{bin} and type  \texttt{./PROCESS\_GUI.exe} to launch the application.

\end{enumerate}


\begin{thebibliography}{99}
\raggedright

\bibitem{git}
\href{http://git-scm.com/}{Git version control system}
\url{http://git-scm.com/}


\end{thebibliography}



\end{document}
